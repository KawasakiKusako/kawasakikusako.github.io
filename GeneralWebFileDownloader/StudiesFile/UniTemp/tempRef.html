<html>
<head>
<title>Title</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
Ahn, M. J. and Y. C. Chen (2022). &quot;Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(2).<p>
Government employees play a critical role in adopting and using new technologies in government, and their attitude and willingness to use them matter in creating a sustainable and meaningful digital transformation. This study explores how the perception of government employees shapes the willingness to support the use of AI technologies in government. Based on a survey data on current government employees in the U.S., our analysis reveals that the willingness to implement and use AI technologies in government was contingent upon a series of positive and negative perceptions about the new technologies, long-term outlook on the role of AI technologies in society, and the familiarity and experience in using some form of AI applications in the past. In particular, the perception of AI enhancing the efficiency and effectiveness of the work and a positive and longer-term outlook on AI's future about human labor (as an assistant or a competitor), the perception of the technology's ultimate harm or benefit (does it harm or benefit humanity), its ability to eventually make ethical and moral judgments influenced the willingness to support AI technologies in government. A substantial proportion of the government employees in the survey sample responded that they had experienced using some form of AI applications in their work and this familiarity had a strong positive influence on their support for AI. Our findings point to the importance of training the government employees in AI technologies to improve their understanding and perception about the new technologies as well as their potentials in government that will foster a culture of innovation toward sustainable and impactful digital transformation.<p>
<p>
Alishani, A., et al. (2025). &quot;Public Encounters and Government Chatbots: When Servers Talk to Citizens.&quot; <u>PUBLIC ADMINISTRATION REVIEW</u>.<p>
Public service providers around the world are now offering chatbots to answer citizens' questions and deliver digital services. Using these artificial intelligence-powered technologies, citizens can engage in conversations with governments through systems that mimic face-to-face interactions and adjust their use of natural language to citizens' communication styles. This paper examines emerging experiences with chatbots in government interactions, with a focus on exploring what public administration practitioners and scholars should expect from chatbots in public encounters. Furthermore, it seeks to identify what gaps exist in the general understanding of digital public encounters.<p>
<p>
Allan, K., et al. (2025). &quot;Stereotypical bias amplification and reversal in an experimental model of human interaction with generative artificial intelligence.&quot; <u>ROYAL SOCIETY OPEN SCIENCE</u> <b>12</b>(4).<p>
Stereotypical biases are readily acquired and expressed by generative artificial intelligence (AI), causing growing societal concern about these systems amplifying existing human bias. This concern rests on reasonable psychological assumptions, but stereotypical bias amplification during human-AI interaction relative to pre-existing baseline levels has not been demonstrated. Here, we use previous psychological work on gendered character traits to capture and control gender stereotypes expressed in character descriptions generated by Open AI's GPT3.5. In four experiments (N = 782) with a first impressions task, we find that unexplained ('black-box') character recommendations using stereotypical traits already convey a potent persuasive influence significantly amplifying baseline stereotyping within first impressions. Recommendations that are counter-stereotypical eliminate and effectively reverse human baseline bias, but these stereotype-challenging influences propagate less well than reinforcing influences from stereotypical recommendations. Critically, the bias amplification and reversal phenomena occur when GPT3.5 elaborates on the core stereotypical content, although GPT3.5's explanations propagate counter-stereotypical influence more effectively and persuasively than black-box recommendations. Our findings strongly imply that without robust safeguards, generative AI will amplify existing bias. But with safeguards, existing bias can be eliminated and even reversed. Our novel approach safely allows such effects to be studied in various contexts where gender and other bias-inducing social stereotypes operate.<p>
<p>
Al-Shamaileh, O., et al. (2025). &quot;Talking Tech in Education: A Systematic Review of Chatbot Evaluation, Methods, Communication Modalities, and Impact.&quot; <u>INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION</u>.<p>
This systematic review investigates how chatbots are evaluated and adopted in education; namely the methods used to assess their effectiveness, their communication modalities, and their benefits and challenges. Following the PRISMA reporting guidelines a comprehensive search was conducted across seven academic databases, covering studies published between 2014 and 2024, resulting in 124 empirical studies based on inclusion and exclusion criteria. Thematic analysis focused on evaluation criteria, advantages, and disadvantages, while data collection methods and communication modalities were analyzed descriptively. Eight key themes were identified in the assessment of educational chatbots, including technology acceptance, learning outcomes and usability. Surveys were the most common data collection method followed by interviews. Text modality dominated chatbot communication, while multimodal formats were rarely used. Reported benefits included 24/7 availability, personalized feedback, and improved motivation. However, challenges such as technical issues and academic integrity concerns were noted. Future research should explore longitudinal impacts and more inclusive assessment frameworks.<p>
<p>
Amini, M., et al. (2025). &quot;Proposing a framework for ethical use of AI in academic writing based on a conceptual review: implications for quality education.&quot; <u>INTERACTIVE LEARNING ENVIRONMENTS</u>.<p>
Aligned with the United Nations Sustainable Development Goal 4 (Quality Education), this paper addresses the ethical use of Artificial Intelligence in academic writing. While AI tools offer unprecedented opportunities for personalized learning and efficiency, their unregulated use raises significant ethical challenges. Through a systematic conceptual review, this study synthesizes existing ethical frameworks and identifies gaps in practical guidance. It proposes a novel, student-centered framework grounded on four pillars: (1) Validation and Source Verification, ensuring AI-generated content accuracy; (2) Transparency and Acknowledgment, promoting honesty by disclosing AI assistance; (3) Context-Dependent Similarity Index, adopting flexible thresholds for AI content usage depending on the academic context; and (4) Direct Source Linking, encouraging proper citation practices with accessible references. The study advocates for embedding this framework into educational policies and AI literacy curricula to empower students to harness AI responsibly, thereby safeguarding educational quality and fostering a culture of transparency and ethical scholarship.<p>
<p>
Androutsopoulou, A., et al. (2019). &quot;Transforming the communication between citizens and government through AI-guided chatbots.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(2): 358-367.<p>
Driven by 'success stories' reported by private sector firms, government agencies have also started adopting various Artificial Intelligence (AI) technologies in diverse domains (e.g. health, taxation, and education); however, extensive research is required in order to exploit the full potential of AI in the public sector, and leverage various AI technologies to address important problems/needs. This paper makes a contribution in this direction: it presents a novel approach, as well as the architecture of an ICT platform supporting it, for the advanced exploitation of a specific AI technology, namely chatbots, in the public sector in order to address a crucial issue: the improvement of communication between government and citizens (which has for long time been problematic). The proposed approach builds on natural language processing, machine learning and data mining technologies, and leverages existing data of various forms (such as documents containing legislation and directives, structured data from government agencies' operational systems, social media data, etc.), in order to develop a new digital channel of communication between citizens and government. Making use of appropriately structured and semantically annotated data, this channel enables 'richer' and more expressive interaction of citizens with government in everyday language, facilitating and advancing both information seeking and conducting of transactions. Compared to existing digital channels, the proposed approach is appropriate for a wider range of citizens' interactions, with higher levels of complexity, ambiguity and uncertainty. In close co-operation with three Greek government agencies (the Ministry of Finance, a social security organization, and a big local government organization), this approach has been validated through a series of application scenarios.<p>
<p>
Bareis, J. and C. Katzenbach (2022). &quot;Talking AI into Being: The Narratives and Imaginaries of National AI Strategies and Their Performative Politics.&quot; <u>SCIENCE TECHNOLOGY &amp; HUMAN VALUES</u> <b>47</b>(5): 855-881.<p>
How to integrate artificial intelligence (AI) technologies in the functioning and structures of our society has become a concern of contemporary politics and public debates. In this paper, we investigate national AI strategies as a peculiar form of co-shaping this development, a hybrid of policy and discourse that offers imaginaries, allocates resources, and sets rules. Conceptually, the paper is informed by sociotechnical imaginaries, the sociology of expectations, myths, and the sublime. Empirically we analyze AI policy documents of four key players in the field, namely China, the United States, France, and Germany. The results show that the narrative construction of AI strategies is strikingly similar: they all establish AI as an inevitable and massively disrupting technological development by building on rhetorical devices such as a grand legacy and international competition. Having established this inevitable, yet uncertain, AI future, national leaders proclaim leadership intervention and articulate opportunities and distinct national pathways. While this narrative construction is quite uniform, the respective AI imaginaries are remarkably different, reflecting the vast cultural, political, and economic differences of the countries under study. As governments endow these imaginary pathways with massive resources and investments, they contribute to coproducing the installment of these futures and, thus, yield a performative lock-in function.<p>
<p>
Bhushan, A. and P. Misra (2025). &quot;Unlocking the potential: multimodal AI in biotechnology and digital medicine-economic impact and ethical challenges.&quot; <u>NPJ DIGITAL MEDICINE</u> <b>8</b>(1).<p>
Artificial Intelligence (AI) is revolutionizing biotechnology by accelerating advancements in drug discovery, genomics, medical imaging, and personalized medicine, thereby enhancing efficiency and reducing healthcare costs. This review emphasizes the transformative potential of multimodal AI-systems that integrate diverse data types such as genomic, clinical, and imaging data-to deliver more accurate and holistic biomedical insights. We explore AI's economic impact, role in driving innovation, and implications for both researchers and policymakers. Additionally, the review addresses key challenges, including data quality, algorithmic transparency, and ethical concerns, highlighting the urgent need for explainable AI models, robust regulatory frameworks, and equitable implementation to ensure responsible and impactful adoption across global healthcare systems.<p>
<p>
Bortolo, G. M., et al. (2023). &quot;Sustainable, technological, and innovative challenges post Covid-19 in health, economy, and education sectors.&quot; <u>TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE</u> <b>190</b>.<p>
The impact of the Covid-19 pandemic has caused an evolution in the business use of Big Data, Artificial Intelligence and New Technologies in general. The general objective of the article is to assess how this process developed during the pandemic in the use and standardization of Big Data, digitalization, the use of data in the private sector and in the public administration and to assess whether it has been used to modernize and digitalize the post-pandemic society. The specific objectives of the article are: 1) the impact of new technologies on society during confinement; 2) to understand the use of Big Data for the creation of new products and businesses and 3) to assess which businesses and companies and from which economic sectors have emerged, which have been transformed and which have disappeared.<p>
<p>
Campion, A., et al. (2022). &quot;Overcoming the Challenges of Collaboratively Adopting Artificial Intelligence in the Public Sector.&quot; <u>SOCIAL SCIENCE COMPUTER REVIEW</u> <b>40</b>(2): 462-477.<p>
Despite the current popularity of artificial intelligence (AI) and a steady increase in publications over time, few studies have investigated AI in public contexts. As a result, assumptions about the drivers, challenges, and impacts of AI in government are far from conclusive. By using a case study that involves a large research university in England and two different county councils in a multiyear collaborative project around AI, we study the challenges that interorganizational collaborations face in adopting AI tools and implementing organizational routines to address them. Our findings reveal the most important challenges facing such collaborations: a resistance to sharing data due to privacy and security concerns, insufficient understanding of the required and available data, a lack of alignment between project interests and expectations around data sharing, and a lack of engagement across organizational hierarchy. Organizational routines capable of overcoming such challenges include working on-site, presenting the benefits of data sharing, reframing problems, designating joint appointments and boundary spanners, and connecting participants in the collaboration at all levels around project design and purpose.<p>
<p>
Campion, A., et al. (2020). &quot;Managing Artificial Intelligence Deployment in the Public Sector.&quot; <u>COMPUTER</u> <b>53</b>(10): 28-37.<p>
There is a scarcity of empirical evidence surrounding the challenges and approaches to artificial intelligence deployment. Using data analytics, our study moves from speculation to gathering evidence. Our findings show that most challenges arise during implementation and relate to skills, culture, and resistance to share information driven by data challenges.<p>
<p>
Carlsson, V. and M. Ronnblom (2022). &quot;From politics to ethics: Transformations in EU policies on digital technology.&quot; <u>TECHNOLOGY IN SOCIETY</u> <b>71</b>.<p>
Artificial intelligence (AI) and digitalisation have become an integral part of public governance. While digital technology is expected to enhance neutrality and accuracy in decision-making, it raises concerns about the status of public values and democratic principles. Guided by the theoretical concepts of input, throughput and output democracy, this article analyses how democratic principles have been interpreted and defended in EU policy formulations relating to digital technology over the last decade. The emergence of AI policy has changed the conditions for democratic input and throughput legitimacy, which is an expression of a shift in power and in-fluence between public and private sectors. Democratic input values in AI production are promoted by ethical guidelines directed towards the industry, while democratic throughput, e.g., accountability and transparency, receive less attention in EU AI policy. This indicates future political implications for the ability of citizens to influence technological change and pass judgement on accountable actors.<p>
<p>
Cecez-Kecmanovic, D. (2025). &quot;Ethics in the world of automated algorithmic decision-making - A Posthumanist perspective.&quot; <u>INFORMATION AND ORGANIZATION</u> <b>35</b>(3).<p>
The grand humanist project of technological advancements has culminated in fascinating intelligent technologies and AI-based automated decision-making systems (ADMS) that replace human decision-makers in complex social processes. Widespread use of ADMS, underpinned by humanist values and ethics, it is claimed, not only contributes to more effective and efficient, but also to more objective, non-biased, fair, responsible, and ethical decision-making. Growing literature however shows paradoxical outcomes: ADMS use often discriminates against certain individuals and groups and produces detrimental and harmful social consequences. What is at stake is the reconstruction of reality in the image of ADMS, that threatens our existence and sociality. This presents a compelling motivation for this article which examines a) on what bases are ADMS claimed to be ethical, b) how do ADMS, designed and implemented with the explicit aim to act ethically, produce individually and socially harmful consequences, and c) can ADMS, or more broadly, automated algorithmic decision-making be ethical. This article contributes a critique of dominant humanist ethical theories underpinning the development and use of ADMS and demonstrates why such ethical theories are inadequate in understanding and responding to ADMS' harmful consequences and emerging ethical demands. To respond to such ethical demands, the article contributes a posthumanist relational ethics (that extends Barad's agential realist ethics with Zigon's relational ethics) that enables novel understanding of how ADMS performs harmful effects and why ethical demands of subjects of decision-making cannot be met. The article also explains why ADMS are not and cannot be ethical and why the very concept of automated decision-making in complex social processes is flowed and dangerous, threatening our sociality and humanity.<p>
<p>
Chen, T. and M. Gasco-Hernandez (2024). &quot;Uncovering the Results of AI Chatbot Use in the Public Sector: Evidence from US State Governments.&quot; <u>PUBLIC PERFORMANCE &amp; MANAGEMENT REVIEW</u>.<p>
The use of artificial intelligence (AI) chatbots in the public sector worldwide has increased in recent years. Despite its increasing use, public administration research in this area faces some limitations. First, much of the current research is theoretical and normative, lacking substantial empirical data to assess the results of chatbots. Second, the specific effects of chatbots on government organization operations and their interactions with the public are not well understood. The purpose of this empirical study is to explore how chatbots influence government operations and their relationship with citizens. We conducted in-depth interviews with officials and employees from twenty-two state agencies in the United States. Leveraging insights from public sector innovation and digital transformation literature, our study reveals various process- and product-related outputs and outcomes within organizations and in government-citizen interactions stemming from chatbot use.<p>
<p>
Chiu, T. K. F., et al. (2023). &quot;Systematic literature review on opportunities, challenges, and future research recommendations of artificial intelligence in education.&quot; <u>Computers and Education Artificial Intelligence</u> <b>4</b>: 100118-100118.<p>
<p>
Cortes-Cediel, M. E., et al. (2023). &quot;Trends and challenges of e-government chatbots: Advances in exploring open government data and citizen participation content.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(4).<p>
In this paper, we propose a conceptual framework composed of a number of e-government, implementation and evaluation-oriented variables, with which we jointly analyze chatbots presented in the research literature and chatbots deployed as public services in Spain at national, regional and local levels. As a result of our holistic analysis, we identify and discuss current trends and challenges in the development and evaluation of chatbots in the public administration sector, such as focusing the use of the conversational agents on the search for government information, documents and services -leaving citizen consultation and collaboration aside-, and con-ducting preliminary evaluations of prototypes in limited studies, lacking experiments on deployed systems, with metrics beyond effectiveness and usability -e.g., metrics related to the generation of public values. Addressing some of the identified challenges, we build and evaluate two novel chatbots that present advances in the access to open government data and citizen participation content. Moreover, we come up with additional, potential research lines that may be considered in the future for a new generation of e-government chatbots.<p>
<p>
de Sousa, W. G., et al. (2019). &quot;How and where is artificial intelligence in the public sector going? A literature review and research agenda.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(4).<p>
To obtain benefits in the provision of public services, managers of public organizations have considerably increased the adoption of artificial intelligence (AI) systems. However, research on AI is still scarce, and the advance of this technology in the public sector, as well as the applications and results of this strategy, need to be systematized. With this goal in mind, this paper examines research related to AI as applied to the public sector. A review of the literature covering articles available in five research databases was completed using the PRISMA protocol for literature reviews. The search process yielded 59 articles within the scope of the study out of a total of 1682 studies. Results show a growing trend of interest in AI in the public sector, with India and the US as the most active countries. General public service, economic affairs, and environmental protection are the functions of government with the most studies related to AI. The Artificial Neural Networks (ANN) technique is the most recurrent in the investigated studies and was pointed out as a technique that provides positive results in several areas of its application. A research framework for AI solutions for the public sector is presented, where it is demonstrated that policies and ethical implications of the use of AI permeate all layers of application of this technology and the solutions can generate value for functions of government. However, for this, a prior debate with society about the use of AI in the public sector is recommended.<p>
<p>
Desiere, S. and L. Struyven (2021). &quot;Using Artificial Intelligence to classify Jobseekers: The Accuracy-Equity Trade-off.&quot; <u>JOURNAL OF SOCIAL POLICY</u> <b>50</b>(2): 367-385.<p>
Artificial intelligence (AI) is increasingly popular in the public sector to improve the cost-efficiency of service delivery. One example is AI-based profiling models in public employment services (PES), which predict a jobseeker's probability of finding work and are used to segment jobseekers in groups. Profiling models hold the potential to improve identification of jobseekers at-risk of becoming long-term unemployed, but also induce discrimination. Using a recently developed AI-based profiling model of the Flemish PES, we assess to what extent AI-based profiling 'discriminates' against jobseekers of foreign origin compared to traditional rule-based profiling approaches. At a maximum level of accuracy, jobseekers of foreign origin who ultimately find a job are 2.6 times more likely to be misclassified as 'high-risk' jobseekers. We argue that it is critical that policymakers and caseworkers understand the inherent trade-offs of profiling models, and consider the limitations when integrating these models in daily operations. We develop a graphical tool to visualize the accuracy-equity trade-off in order to facilitate policy discussions.<p>
<p>
Distel, B. and I. Lindgren (2023). &quot;A matter of perspective: Conceptualizing the role of citizens in E-government based on value positions.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(4).<p>
Citizens are oftentimes the central unit of analysis in e-government research and treated as one of the stake-holders receiving the most benefits from public sector digitalization. Still, they are mostly described in general terms, and it remains unclear what roles they can assume in relation to e-government. Different understandings of the citizens' role in e-government may impact research, because they entail different axioms mainly in relation to the technological frame for e-government but also for the citizens' relationship to public sector organizations in general. The aim of this article is to investigate and conceptualize the citizens' role in e-government based on public value positions. We depart from Rose et al.'s (2015) framework of value positions for managing e-gov-ernment. After reviewing and analyzing extensive research on e-government, we use this framework to contribute a clarification of the citizens' role in each value position. Our analysis shows that the ideal citizen is conceptualized differently across the four value positions; ranging from an external entity that should service themselves using digital self-services, to an engaged agent that should be actively involved in policy making and service delivery. In addition to this new perspective on the citizens' role in e-government, we contribute with an extension of the public value positions framework. The extended framework presented in this article makes these differences visible and we discuss consequences of the citizens' role in e-government for other dimensions of the framework.<p>
<p>
Dubey, R., et al. (2023). &quot;Dynamic digital capabilities and supply chain resilience: The role of government effectiveness.&quot; <u>INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS</u> <b>258</b>.<p>
Organizations in recent times are increasingly investing in building supply chain resilience following disruptions due to natural disasters, geo-political crises, and pandemics. A lack of government support has exacerbated the disruption to supply chains in some regions of the world. The positive influence of digitalization on social in-clusion, government accountability, and creating a more open environment is well understood. Despite this, different countries have shown varying degrees of digital responsiveness during the pandemic as they attempted to deal with the effects of various COVID strains. The influence of government policies on the supply chain has not been examined in the literature so far and, hence, to address this research gap, we examine the interaction effect of government support effectiveness i.e., tax credits, interest deferral, digital investment, soft loans on dynamic capabilities i.e., digital adaptabilities and digital agilities and on supply chain resilience, using a multi -method approach. To understand how digital adaptability and agility improve supply chain resilience, we conducted 13 semi-structured interviews. Additionally, we pretested our measurement instrument using quali-tative semi-structured interviews to validate our hypothesized relationships. We collected data at a specific point of time using a survey-based instrument (N = 203) to address our research questions. Based on data analyses of both the qualitative and survey-based data, our findings indicate that digital adaptability is an important driver of digital agility. Furthermore, the results indicate that government effectiveness is crucial to enhancing supply chain resilience by enhancing digital adaptability and agility. Our research makes some useful contributions to the dynamic capability view by enhancing theoretical understanding, of the role of government in building digital capabilities in uncertain times, to improve supply chain resilience. It also bridges the research gaps be-tween macro and micro perspectives, as identified by management scholars. Lastly, we noted the weaknesses and limitations in the study and therefore we have offered multiple research directions forward, that could help researchers to further develop our current work.<p>
<p>
Engstrom, D. F. and A. Haim (2023). &quot;Regulating Government AI and the Challenge of Sociotechnical Design.&quot; <u>ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE</u> <b>19</b>: 277-298.<p>
Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.<p>
<p>
Eom, S.-J. and J. Lee (2022). &quot;Digital government transformation in turbulent times: Responses, challenges, and future direction.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(2).<p>
We are living in turbulent times, with the threats of COVID-19 and related social conflicts. Digital transformation is not an option but a necessity for governments to respond to these crises. It has become imperative for governments worldwide to enhance their capacity to strategically use emerging digital technologies and develop innovative digital public services to confront and overcome the pandemic. With the rapid development of digital technologies, digital government transformation (DGT) has been legitimated in response to the pandemic, contributing to innovative efficacy, but it also has created a set of challenges, dilemmas, paradoxes, and ambiguities. This special issue's primary motive is to comprehensively discuss the promises and challenges DGT presents. It focuses on the nature of the problems and the dilemmatic situation in which to use the technologies. Furthermore, it covers government capacity and policy implications for managerial and institutional reforms to respond to the threats and the uncertainty caused by disruptive digitalization in many countries. To stimulate discussion of the theme of this special issue, this editorial note provides an overview of previous literature on DGT as a controlling measure of the pandemic and the future direction of research and practice on DGT.<p>
<p>
Fatima, S., et al. (2020). &quot;National strategic artificial intelligence plans: A multi-dimensional analysis.&quot; <u>ECONOMIC ANALYSIS AND POLICY</u> <b>67</b>: 178-194.<p>
Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national -level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities. (c) 2020 Economic Society of Australia, Queensland. Published by Elsevier B.V. All rights reserved.<p>
<p>
Galaz, V., et al. (2021). &quot;Artificial intelligence, systemic risks, and sustainability.&quot; <u>TECHNOLOGY IN SOCIETY</u> <b>67</b>.<p>
Automated decision making and predictive analytics through artificial intelligence, in combination with rapid progress in technologies such as sensor technology and robotics are likely to change the way individuals, communities, governments and private actors perceive and respond to climate and ecological change. Methods based on various forms of artificial intelligence are already today being applied in a number of research fields related to climate change and environmental monitoring. Investments into applications of these technologies in agriculture, forestry and the extraction of marine resources also seem to be increasing rapidly. Despite a growing interest in, and deployment of AI-technologies in domains critical for sustainability, few have explored possible systemic risks in depth. This article offers a global overview of the progress of such technologies in sectors with high impact potential for sustainability like farming, forestry and the extraction of marine resources. We also identify possible systemic risks in these domains including a) algorithmic bias and allocative harms; b) unequal access and benefits; c) cascading failures and external disruptions, and d) trade-offs between efficiency and resilience. We explore these emerging risks, identify critical questions, and discuss the limitations of current governance mechanisms in addressing AI sustainability risks in these sectors.<p>
<p>
Gerli, P., et al. (2021). &quot;Beyond contact-tracing: The public value of eHealth application in a pandemic.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>38</b>(3).<p>
This study adopts a public value perspective to examine the eHealth services deployed by national and regional governments to contain the coronavirus (Covid-19) pandemic, including symptoms checkers, information portals and contact-tracing applications. We analyse 50 cases of eHealth applications adopted in 25 European Economic Area (EEA) and outline how these systems and technologies map against four dimensions of public value: user orientation, participation, legality and equity. Our findings reveal that the public value of the eHealth applications adopted in the context of the current pandemic is affected by both endogenous and exogenous factors that undermine their ability to improve the quality of healthcare services and social wellbeing. We conclude by suggesting areas for further research to address such factors and the trade-offs emerging between different dimensions of public value.<p>
<p>
Gesk, T. S. and M. Leyer (2022). &quot;Artificial intelligence in public services: When and why citizens accept its usage.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(3).<p>
Interest in implementing artificial intelligence (AI)-based software in the public sector is growing. First implementations and research in individual public services have already been carried out; however, a better understanding of citizens' acceptance of this technology is missing in the public sector, as insights from the private sector cannot be transferred directly. For this purpose, we conduct policy-capturing experiments to analyze AI's acceptance in six representative scenarios. Based on behavioral reasoning theory, we gather evidence from 329 participants. The results show that AI solutions in general public services are preferred over those provided by humans, but specific services are still a human domain. Further analyses show that the major drivers toward acceptance are the reasons against AI. The results contribute to understanding of when and why AI is accepted in public services. Public administration can use the results to identify AI-based software to invest in and communicate their usage to perceive such investments' high acceptance rates.<p>
<p>
Guenduez, A. A. and T. Mettler (2023). &quot;Strategically constructed narratives on artificial intelligence: What stories are told in governmental artificial intelligence policies?&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(1).<p>
What stories are told in national artificial intelligence (AI) policies? Combining the novel technique of structural topic modeling (STM) and qualitative narrative analysis, this paper examines the policy narratives in 33 coun-tries' AI policies. We uncover six common narratives that are dominating the political agenda concerning AI. Our findings show that the policy narratives' saliences vary across time and countries. We make several contributions. First, our narratives describe well-grounded, supportable conceptions of AI among governments, and show that AI is still a fairly novel, multilayered, and controversial phenomenon. Building on the premise that human sensemaking is best represented and supported by narration, we address the applied rhetoric of governments to either minimize the risks or exalt the opportunities of AI. Second, we uncover the four prominent roles gov-ernments seek to take concerning AI implementation: enabler, leader, regulator, and/or user. Third, we make a methodological contribution toward data-driven, computationally-intensive theory development. Our method-ological approach and the identified narratives present key starting points for further research.<p>
<p>
Guo, Z. and F. Cugurullo (2025). &quot;Smart Urbanism Through Artificial Intelligence (AI)-Megaprojects: The Case of China's Healthcare Services.&quot; <u>PUBLIC ADMINISTRATION AND DEVELOPMENT</u> <b>45</b>(3): 296-312.<p>
Urban Artificial Intelligence (AI) technologies are increasingly being piloted in cities worldwide, constituting a critical element in the evolution of contemporary and future smart cities. Although there is a growing body of research on the integration of AI into healthcare and smart city systems, the specific intersection of urban AI and healthcare in the context of state-led megaprojects remains insufficiently examined, particularly through empirical case studies grounded in local socio-political dynamics. This paper investigates how urban AI impacts healthcare services in a mega-hospital, addressing this significant gap in the literature. The study's contribution is threefold. First, it synthesizes the developmental trajectory of smart healthcare in China, highlighting the integration of AI technologies into the healthcare sector. Second, through an in-depth case study of the Guangdong Second Provincial General Hospital, it examines three distinct facets of smart applications within the hospital-focusing on patients, medical staff, and hospital administration-to elucidate the characteristics and dynamics of AI megaprojects in healthcare. Third, it delves into the main challenges and advantages of these AI-driven megaprojects in healthcare management and administration, and proposes policy recommendations based on the case study and identified issues and benefits. The findings reveal that while the integration of AI enhances operational efficiency and patient care outcomes, it also introduces challenges related to data privacy, ethical considerations, and infrastructural demands. The study underscores the necessity for integrated strategies that balance technological advancement with public welfare and urban sustainability. By illuminating the complex interplay between technological innovation, healthcare administration, and urban governance, this paper offers valuable insights for policymakers, urban planners, and healthcare administrators aiming to foster sustainable smart city development.<p>
<p>
Hansen, J. A. and L. Tummers (2020). &quot;A Systematic Review of Field Experiments in Public Administration.&quot; <u>PUBLIC ADMINISTRATION REVIEW</u> <b>80</b>(6): 921-931.<p>
Field experiments have become popular in public administration. By allowing for the identification of causal effects in realistic settings, field experiments may become central in several research agendas of relevance to the field. Conducting field experiments is difficult and problems often occur along the way. However, researchers new to the method have few resources in public administration to consider the problems that arise when conducting field experiments. This systematic review identifies 42 field experiments in public administration and serves as an introduction to field experiments in public administration. The article discusses how field experiments developed over time and highlights trends in field experimentation in public administration. It then discusses issues to consider when designing field experiments. Among these are costs, practicality, ethics, and validity. Finally, the authors suggest a future research agenda for public administration field experiments.<p>
<p>
Hao, X. L., et al. (2024). &quot;The impact of digital government on corporate green innovation: Evidence from China.&quot; <u>TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE</u> <b>206</b>.<p>
Governmental digital transformation is a critical visible manifestation of the digital economy. It plays a crucial role in driving green innovation and encouraging enterprise development. This study examined the impact of digital government (DG) initiatives on corporate green innovation (GI) among key stakeholders in China's economy-non-state-owned enterprises, technology-intensive firms, and high-tech companies. This study analyzed panel data from listed companies in China between 2009 and 2020. The findings indicate that establishing DG has effectively stimulated the impetus for GI among these enterprises, particularly in driving advancements within highly digitized enterprises. This underscores the positive impact of DG construction during China's initial stage of digital economic development. The digitization of government operations lessens the tax load on local businesses. It also notably enhances the business environment within these enterprises. Moreover, it mitigates information disparities between the government and businesses while actively fostering green innovation in enterprises. However, political connections can reduce this impact. The findings of this study illustrate significant policy implications for local governments to benefit from the strategic opportunities provided by digital technology while strengthening the foundational support for the green innovation of enterprises.<p>
<p>
Heinisuo, E., et al. (2025). &quot;Navigating AI Implementation in Local Government: Addressing Dilemmas by Fostering Mutuality and Meaningfulness.&quot; <u>INFORMATION SYSTEMS FRONTIERS</u>.<p>
This study explores AI-enabled local public service provisioning, especially dilemmas of the mutual and meaningful development process. Theoretically, it builds on the current literature on AI implementation in the public sector and relates it to the theorisations of mutuality and meaningfulness. Empirically, it examines the experiences of public agents in a qualitative case study of chatbot development by the City of Oulu, Finland. The study concludes six factors that are constructed into three interconnected dilemma pairs to examine cross-cutting problematic decision-making scenarios and provide reconciliations through mutuality and meaningfulness.<p>
<p>
Hemesath, S. and M. Tepe (2024). &quot;Public value positions and design preferences toward AI-based chatbots in e-government. Evidence from a conjoint experiment with citizens and municipal front desk officers.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>41</b>(4).<p>
Developing a chatbot to handle citizen requests in a municipal office requires multiple design choices. We use public value theory to test how value positions shape these design choices. In a conjoint experiment, we asked German citizens (n = 1690) and front desk officers in municipalities (n = 267) to evaluate hypothetical chatbot designs that differ in their fulfillment of goals derived from different value positions: (1) maintaining security, privacy, and accountability, (2) improving administrative performance, and (3) improving user-friendliness and empathy. Experimental results show that citizens prefer chatbots programmed by domestic firms, value chatbots taking routine decisions excluding discretion, and strongly prefer human intervention when conversations fail. While altering the salience of public sector values through priming does not affect citizens' design choices consistently, we find systematic differences between citizens and front desk officers. However, these differences are qualitative rather than fundamental. We conclude that citizens and front desk officers share public values that provide a sufficient basis for chatbot designs that overcome a potential legitimacy gap of AI in citizens-state service encounters.<p>
<p>
Hillo, J., et al. (2025). &quot;Algorithmic Governance: Experimental Evidence on Citizens' and Public Administrators' Legitimacy Perceptions of Automated Decision-Making.&quot; <u>PUBLIC ADMINISTRATION</u>.<p>
This article investigates legitimacy perceptions of automated decision-making (ADM) among public administrators and citizens. Views of public administrators, who exercise discretion over policy implementation, reflect readiness to integrate AI into decision-making. Governing by AI ought also to be responsive to the view of citizens, whose support democratic governing ultimately rests on. As AI use in governing grows, understanding the elite-mass opinion congruence is crucial, and incongruence suggest misalignment between citizen preferences and policy implementation. Using randomized survey experiments conducted among Finnish toplevel public administrators (N = 842) and a representative sample of citizens (N = 3245), we compare the legitimacy effects of algorithmic transparency and human discretion over decision-making in the context of child protection services. Transparency and human discretion enhance perceived legitimacy, with larger treatment effects among administrators. The study concludes that ADM legitimacy theories extend to a Nordic welfare context.<p>
<p>
Hosseini Tabaghdehi, S. A. and O. Ayaz (2025). &quot;AI ethics in action: a circular model for transparency, accountability and inclusivity.&quot; <u>JOURNAL OF MANAGERIAL PSYCHOLOGY</u>.<p>
Purpose - Drawing upon a circular model proposition, Kantian ethics is employed to explore how ethical considerations within AI translate into concrete actions that prioritize transparency, privacy, inclusivity and equality. Additionally, agency theory is applied to understand the relevance of fairness in the interactions between agents, principals and algorithmic systems, particularly in the creation of value through digital platforms. Design/methodology/approach - A review of literature on ethical concerns within the AI ecosystem is conducted, proposing a unifying ethical principle and standards. The circular model for ethics in action is then developed, emphasising the responsible use of AI and its role in capturing and creating social value, ultimately contributing to sustainable organizational outcomes. The model also highlights key drivers that shape the ethical framing of AI, as well as the influence of the institutional context on its adoption and effectiveness. Findings - Responsible use of AI positively affects organizational performance and the digital ecosystem via the psychological mechanism of ethical identity. Ethical standards and regulations are the global requirements for the AI ecosystem that are required for achieving a sustainable digital society. Research limitations/implications - This study contributes to a comprehensive understanding of the responsible use of AI's and its practical and theoretical implications for organizations in the current digital ecosystem. Lack of global understanding, awareness and implementation of ethical practice in the AI ecosystem is not yet developed and practice. Future researchers can design a cross-border ethical framework to overcome these limitations. Organizations targeting to increase responsible digital interactions can benefit from maintaining ethical principles through responsible labourers, leaders and all stakeholders involved in the ecosystem. Practical implications - This study offers practical guidance for businesses, policymakers and AI practitioners on the ethical use of AI. It emphasizes the need for robust data governance, a &quot;human-first&quot; approach focusing on privacy and accountability and alignment with ethical standards. Given AI's global reach, international cooperation and standard-setting are essential to navigate diverse regulatory and cultural contexts. The paper also highlights the importance of ethics education for AI developers and practitioners. Investing in training that integrates technical skills with ethical awareness will help build a responsible AI workforce capable of addressing societal impacts and maintaining public trust. Social implications - This study underscores the urgent need for responsible AI adoption, highlighting risks such as bias, lack of transparency and privacy concerns. As AI reshapes work, decision-making and governance, its social impact grows - potentially deepening inequalities if left unchecked. The study calls for explainable, fair and inclusive AI systems guided by ethical frameworks that respect human dignity. A &quot;human-first&quot; approach ensures AI supports-not replaces-human agency. By fostering transparency, accountability and cultural sensitivity, organizations can build public trust, empower diverse communities and contribute to a more equitable digital future. Ethical leadership and inclusive design are essential to avoid reinforcing systemic harms.Originality/value - This study presents an original approach to integrating ethical considerations into the development and deployment of artificial intelligence, by conceptualizing how transparency, accountability and inclusivity can be embedded throughout the AI ecosystem, fostering trust and responsible innovation. Through a comprehensive examination of ethical principles and requirements, we recommend a set of tools and strategies needed to promote ethical AI practices, mitigate risks and maximize societal benefit. Furthermore, this study serves as a roadmap for building AI systems that prioritize human collaboration and uphold fundamental values in he digital age.<p>
<p>
Huang, C. and X. Yao (2025). &quot;Synergies Among Responsible Artificial Intelligence (RAI), Environmental, Social and Governance (ESG), and Sustainable Development Goals (SDGs).&quot; <u>IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE</u> <b>20</b>(4): 20-41.<p>
This paper explores the synergistic relationships among responsible artificial intelligence (RAI), environmental, social and governance (ESG), and sustainable development goals (SDGs), highlighting how their integration can create opportunities for organizations to enhance societal impact while increasing corporate value and fostering innovation. Through a systematic literature review, this study first provides foundational knowledge related to RAI, ESG, and SDGs, including their origins, core concepts, and main implementation challenges. Then, the relationships between RAI, ESG, and SDGs are examined and discussed through the analysis of connections and synergies among them. Based on this analysis, an integrated framework that synthesizes the relationships among RAI, ESG, and SDGs is proposed, demonstrating how they can be mutually reinforcing when implemented cohesively. Additionally, the paper discusses implications of this integrated approach for multiple stakeholders, while acknowledging implementation challenges and tensions. The study emphasizes the necessity of viewing RAI, ESG, and SDGs as interconnected frameworks rather than individual goals. Through this integrated lens, organizations can align RAI, ESG, and SDGs collectively in their strategic planning and operational practices, thereby promoting more effective and sustainable outcomes while addressing complex societal challenges in the AI era. The research contributes to both theoretical understanding and practical guidance for implementing holistic approaches that harness the transformative potential of AI technologies while ensuring that their development and deployment serve broader sustainability and social responsibility objectives.<p>
<p>
Ignacio Criado, J. and L. O. de Zarate-Alcarazo (2022). &quot;Technological frames, CIOs, and Artificial Intelligence in public administration: A socio-cognitive exploratory study in Spanish local governments.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(3).<p>
Artificial Intelligence (AI) policies and strategies have been designed and adopted in the public sector during the last few years, with Chief Information Officers (CIOs) playing a key role. Using socio-cognitive and institutional approaches on Information Technologies (ITs) in (public) organizations, we consider that the assumptions, expectations, and knowledge (technological frames) of those in charge (CIOs) of designing AI strategies are guiding the future of these emerging systems in the public sector. In this study, we focus on the technological frames of CIOs in the largest Spanish local governments. Based on a survey administered to CIOs leading IT departments, this article presents original data about their technological frames on AI. Our results: (1) provide insights about how CIOs tend to focus on the technological features of AI implementation while often overlook some of the social, political, and ethical challenges in the public sector; (2) expand the theory on AI by enabling the construction of propositions and testable hypotheses for future research in the field. Therefore, the comparative study of technological frames will be key to successfully design and implement AI policies and strategies in the public sector and to tackle future challenges and opportunities.<p>
<p>
Ingrams, A., et al. (2022). &quot;In AI we trust? Citizen perceptions of AI in government decision making.&quot; <u>POLICY AND INTERNET</u> <b>14</b>(2): 390-409.<p>
Using a survey experiment on the topic of tax auditing, we investigate artificial intelligence (AI) use in government decision making through the lenses of citizen red tape and trust. We find that individuals consider an AI-led decision to be lower in red tape and trustworthiness than a decision by a human. We also find that highly complex tasks produce decisions with higher levels of perceived red tape, but that this effect does not vary according to whether the task is AI- or human-led. We argue that researchers and practitioners give more attention to the balance of instrumental and value-based qualities in the design and implementation of AI applications.<p>
<p>
Janssen, M., et al. (2022). &quot;Will Algorithms Blind People? The Effect of Explainable AI and Decision-Makers' Experience on AI-supported Decision-Making in Government.&quot; <u>SOCIAL SCIENCE COMPUTER REVIEW</u> <b>40</b>(2): 478-493.<p>
Computational artificial intelligence (AI) algorithms are increasingly used to support decision making by governments. Yet algorithms often remain opaque to the decision makers and devoid of clear explanations for the decisions made. In this study, we used an experimental approach to compare decision making in three situations: humans making decisions (1) without any support of algorithms, (2) supported by business rules (BR), and (3) supported by machine learning (ML). Participants were asked to make the correct decisions given various scenarios, while BR and ML algorithms could provide correct or incorrect suggestions to the decision maker. This enabled us to evaluate whether the participants were able to understand the limitations of BR and ML. The experiment shows that algorithms help decision makers to make more correct decisions. The findings suggest that explainable AI combined with experience helps them detect incorrect suggestions made by algorithms. However, even experienced persons were not able to identify all mistakes. Ensuring the ability to understand and traceback decisions are not sufficient for avoiding making incorrect decisions. The findings imply that algorithms should be adopted with care and that selecting the appropriate algorithms for supporting decisions and training of decision makers are key factors in increasing accountability and transparency.<p>
<p>
Kankanhalli, A., et al. (2019). &quot;IoT and AI for Smart Government: A Research Agenda.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(2): 304-309.<p>
The Internet of things (IoT) is the network of objects/things that contain electronics, software, sensors, and actuators, which allows these things to connect, interact, and exchange data. The users, sensors, and networks generate huge amounts of data from which governments can develop applications and gain knowledge using Artificial Intelligence (AI) techniques. Thus, IoT and AI can enable the development of valuable services for citizens, businesses, and public agencies, in multiple domains, such as transportation, energy, healthcare, education, and public safety. This guest editorial for the special issue on IoT and AI for Smart Government, identifies the challenges involved in implementing and adopting these technologies in the public sector, and proposes a comprehensive research framework, which includes both IoT and AI elements for smart government transformation. Subsequently, the editorial provides a brief introduction of the six papers in this special issue. Finally, an agenda for future research on IoT and AI for smart government is presented, based on the proposed framework and gaps in existing literature, supported by the papers that were submitted to this special issue. The agenda comprises four directions i.e., conducting domain-specific studies, going beyond adoption studies to examine implementation and evaluation of these technologies, focusing on specific challenges and thus quick wins, and expanding the existing set of research methods and theoretical foundations used.<p>
<p>
Kempeneer, S. and F. Heylen (2023). &quot;Virtual state, where are you? A literature review, framework and agenda for failed digital transformation.&quot; <u>BIG DATA &amp; SOCIETY</u> <b>10</b>(1).<p>
The users, sensors and networks of the Internet of Things generate huge amounts of data. Given the sophisticated (artificially intelligent) algorithms, computing power and software available, we would expect governments to have successfully completed their digital transformation into Jane Fountain's (2001) 'Virtual State'. In practice, despite heavy investments, governments often fail to enact new digital technologies in an efficient, appropriate or fair way. This article provides an overview of techno-rational and socio-political failures and solutions at the macro-, meso- and micro-level to support digital transformation. The reviewed articles suggest a modest approach to digital transformation, with an emphasis on high-quality in-house IT infrastructure and expertise, but also better collaborative networks and strong leadership ensuring human oversight.<p>
<p>
Keppeler, F. (2024). &quot;No Thanks, Dear AI! Understanding the Effects of Disclosure and Deployment of Artificial Intelligence in Public Sector Recruitment.&quot; <u>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</u> <b>34</b>(1): 39-52.<p>
Applications based on artificial intelligence (AI) play an increasing role in the public sector and invoke political discussions. Research gaps exist regarding the disclosure effects-reactions to disclosure of the use of AI applications-and the deployment effect-efficiency gains in data savvy tasks. This study analyzes disclosure effects and explores the deployment of an AI application in a preregistered field experiment (n = 2,000) co-designed with a public organization in the context of employer-driven recruitment. The linear regression results show that disclosing the use of the AI application leads to significantly less interest in an offer among job candidates. The explorative analysis of the deployment of the AI application indicates that the person-job fit determined by the leaders can be predicted by the AI application. Based on the literature on algorithm aversion and digital discretion, this study provides a theoretical and empirical disentanglement of the disclosure effect and the deployment effect to inform future evaluations of AI applications in the public sector. It contributes to the understanding of how AI applications can shape public policy and management decisions, and discusses the potential benefits and downsides of disclosing and deploying AI applications in the public sector and in employer-driven recruitment.<p>
<p>
Kleizen, B., et al. (2023). &quot;Do citizens trust trustworthy artificial intelligence? Experimental evidence on the limits of ethical AI measures in government.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(4).<p>
This study examines the impact of ethical AI information on citizens' trust in and policy support for governmental AI projects. Unlike previous work on direct users of AI, this study focuses on the general public. Two online survey experiments presented participants with information on six types of ethical AI measures: legal compliance, ethics-by-design measures, data-gathering limitations, human-in-the-loop, non-discrimination, and technical robustness. Results reveal that general ethical AI information has little to no effect on trust, perceived trustworthiness or policy support among citizens. Prior attitudes and experiences, including privacy concerns, trust in government, and trust in AI, instead form good predictors. These findings suggest that short-term communication efforts on ethical AI practices have minimal impact. The findings suggest that a more longterm, comprehensive approach is necessary to building trust in governmental AI projects, addressing citizens' underlying concerns and experiences. As governments' use of AI becomes more ubiquitous, understanding citizen responses is crucial for fostering trust, perceived trustworthiness and policy support for AI-based policies and initiatives.<p>
<p>
Koenig, P. D. and G. Wenzelburger (2020). &quot;Opportunity for renewal or disruptive force? How artificial intelligence alters democratic politics.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>37</b>(3).<p>
The increasing adoption of AI profoundly changes the informational foundations of societies. What does this mean for the functioning of liberal democracy, specifically in terms of responsiveness and accountability? The present paper addresses this question by discussing how capabilities of AI affect the informational requirements of the democratic process. Based on a systems theory perspective, the consequences of AI are shown to be wideranging. AI can reduce or increase information deficits of both citizens and decision-makers on the input, throughout, and output level of the political system. While the challenges that AI creates for democratic responsiveness and accountability have a novel technological dimension, they are nonetheless in continuity with existing transparency and accountability problems. Avoiding a negative impact will require institutionalizing suitable governance mechanisms - a task that is challenging already at the throughout and output level, but particularly difficult, and important, at the input level of politics.<p>
<p>
Kuziemski, M. and G. Misuraca (2020). &quot;AI governance in the public sector: Three tales from the frontiers of automated decision-making in democratic settings.&quot; <u>TELECOMMUNICATIONS POLICY</u> <b>44</b>(6).<p>
The rush to understand new socio-economic contexts created by the wide adoption of AI is justified by its far-ranging consequences, spanning almost every walk of life. Yet, the public sector's predicament is a tragic double bind: its obligations to protect citizens from potential algorithmic harms are at odds with the temptation to increase its own efficiency - or in other words - to govern algorithms, while governing by algorithms. Whether such dual role is even possible, has been a matter of debate, the challenge stemming from algorithms' intrinsic properties, that make them distinct from other digital solutions, long embraced by the governments, create externalities that rule-based programming lacks. As the pressures to deploy automated decision making systems in the public sector become prevalent, this paper aims to examine how the use of AI in the public sector in relation to existing data governance regimes and national regulatory practices can be intensifying existing power asymmetries. To this end, investigating the legal and policy instruments associated with the use of AI for strenghtening the immigration process control system in Canada; &quot;optimising&quot; the employment services&quot; in Poland, and personalising the digital service experience in Finland, the paper advocates for the need of a common framework to evaluate the potential impact of the use of AI in the public sector. In this regard, it discusses the specific effects of automated decision support systems on public services and the growing expectations for governments to play a more prevalent role in the digital society and to ensure that the potential of technology is harnessed, while negative effects are controlled and possibly avoided. This is of particular importance in light of the current COVID-19 emergency crisis where AI and the underpinning regulatory framework of data ecosystems, have become crucial policy issues as more and more innovations are based on large scale data collections from digital devices, and the real-time accessibility of information and services, contact and relationships between institutions and citizens could strengthen - or undermine - trust in governance systems and democracy.<p>
<p>
Lahdili, N., et al. (2024). &quot;Artificial Intelligence and Citizen Participation in Governance: Opportunities and Threats.&quot; <u>AMME IDARESI DERGISI</u> <b>57</b>(3): 203-229.<p>
This study seeks to develop a research agenda by looking at the nexus between citizen participation and artificial intelligence (AI). Existing studies have focused more on conceptual, explanatory, and practice-driven aspects of AI and overlooked the lessons, opportunities, and threats that emerge from AI's increased yet complex application in citizen participation processes. Given that AI has the possibility of positively or negatively influencing citizens' participation in governance processes and the high cost of adopting AI-related technologies, this paper considers it important to examine its potential threats and opportunities. To achieve this objective, the study will look at how the use of AI can enhance the participation of citizens in governance activities. The authors argue that there is great potential in enhancing citizen participation in policymaking by deploying AI technologies such as chatbots and machine learning algorithms. This will also impact policymakers' response to citizens' needs by gathering information and recording data, processing information, answering citizens' queries, etc. The study however points to threats such as inadequate computer literacy, cyber-attacks, data privacy, and civil liberties, the cost of adopting AI technologies, and inadequate personnel as having the potential to undermine the successful application of AI in citizen participation processes.<p>
<p>
Li, H. and L. Gu (2025). &quot;Smart Interaction vs. Face-to-Face? Evidence from a Survey Experiment on Perceived Government Responsiveness in China.&quot; <u>JOURNAL OF CHINESE POLITICAL SCIENCE</u>.<p>
Existing research has shown that smart mobile devices have undoubtedly expedited the advancement of government services and narrowed distances in government-citizen interaction. However, a significant oversight in prior research lies in the lack of consideration of users' perceptions regarding mobile applications, because some studies have revealed that certain mobile channels fail to offer a user-friendly experience. This study addresses this research gap by conducting a survey experiment to investigate perceived government responsiveness in both smart and human interaction modes. Drawing inspiration from customer value theory, this study argues that the perceived value of government responsiveness comprises both benefits and costs. Our experimental findings first indicate that the public significantly favors the perceived benefits of smart interaction modes over traditional human modes. More importantly, we find that the public perceives smart interaction modes as more effective in eliciting government responses for consultation and suggestions, compared to handling complaints and assistance-related issues. Regarding the perceived costs associated with seeking assistance and lodging complaints, the public exhibits skepticism towards the quality of services provided by mobile methods. In light of these findings, it is crucial for the government to allocate resources judiciously, capitalizing on the strengths of both smart and human modes of interaction, to optimize the government service ecosystem. The government must persist in refining the quality of mobile services and enhance its responsiveness to public demands during the process of government digital transformation.<p>
<p>
Li, X. and J. Wang (2024). &quot;Should government chatbots behave like civil servants? The effect of chatbot identity characteristics on citizen experience.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>41</b>(3).<p>
Government chatbots are naturally imparted the identity of civil service agents, because they replace human civil servants in providing services on the frontline. However, little is known about whether government chatbots should present key characteristics consistent with their identity. Based on Computers Are Social Actors (CASA) theory and the stereotype content model (SCM), this study explored the effect of various identity characteristics on citizens' experiences in Chinese government chatbots. Valid data were obtained from 705 respondents and analysed using structural equation model, we found that manners, proactivity, conscientiousness, fairness, and professionalisation significantly influence the citizens' experiences, and that task-oriented language style has a negative effect. These effects are partly mediated by perceptions of warmth and competence. These findings contribute theoretically to the literature on chatbot identity and provide implications for incorporating chatbots into the design of e-government context.<p>
<p>
Li, Y., et al. (2025). &quot;Making governance agile: Exploring the role of artificial intelligence in China's local governance.&quot; <u>PUBLIC POLICY AND ADMINISTRATION</u> <b>40</b>(2): 276-301.<p>
As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance-&quot;AI cage&quot; and &quot;AI colleague.&quot; The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.<p>
<p>
Liang, L. and Y. Li (2023). &quot;How does government support promote digital economy development in China? The mediating role of regional innovation ecosystem resilience.&quot; <u>TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE</u> <b>188</b>.<p>
This study investigates how government support affects digital economy development in China and whether regional innovation ecosystem resilience mediates this relationship. Drawing upon a panel data set containing 31 Chinese provinces from 2011 to 2020, an econometric model is constructed for empirical analysis. We find that government support significantly promotes digital economy development. Regional innovation ecosystem resilience plays a full mediating role between government support and digital economy development. In addi-tion, the spatial spillover effects regional innovation ecosystem resilience on digital economy development is also examined. The results show that regional innovation ecosystem resilience has a positive spatial spillover effect on digital economy development. These findings have important implications for the Chinese policy agenda on digital economy development.<p>
<p>
Liang, Z., et al. (2025). &quot;When AI fails, who gets the blame? Citizens' attribution patterns in AI-induced public service failures.&quot; <u>JOURNAL OF CHINESE GOVERNANCE</u>.<p>
Globally, governments have increasingly implemented Artificial Intelligence (AI) in public service delivery and decision-making to replace human officials in the name of improving scalability, cost-effectiveness, and efficiency. However, few empirical studies have explored the challenges citizens face in seeking accountability when government AI agents fail. To fill this gap, this paper investigates how citizens perceive and attribute blame for AI-induced public service failures compared to those caused by human officials, addressing the potential 'accountability deficit' in AI governance. Using Weiner's Attribution Theory as the framework, we conducted three scenario-based experiments with 516 participants. The results revealed that citizens generally blamed AI agents less than government departments due to lower perceptions of controllability over the service task compared to the same failures caused by human officials. However, when AI was identified as outsourced, their blame toward the government was significantly lower. Thus, our findings support the idea that the application of AI in public services introduces uncertainty into governmental reputation and accountability. Overall, this study contributes to the growing body of knowledge on AI in public services by underscoring the importance of developing ethical and legal governance frameworks to address potential accountability deficiencies and blame avoidance in public services using AI.<p>
<p>
Liu, F. K., et al. (2024). &quot;Whether the construction of digital government alleviate resource curse? Empirical evidence from Chinese cities.&quot; <u>RESOURCES POLICY</u> <b>90</b>.<p>
Breaking the resource curse is an inevitable requirement to achieve sustainable development, while the effect of digital government on it still remain as a black box, which forms the initial motivation of this study. Based on the panel data of 282 cities in China from 2015 to 2021, this study applies a dual machine learning model to identify the impact and internal mechanism of digital government construction on resource curse. The result reveals that the construction of digital government has a significant impact on mitigating the degradation of resource curse, and the effect is more significant in the sample of cities in the central and eastern regions, small and mediumsized cities, non -resource cities, and cities with low market segmentation levels. The mechanism analysis shows that digital government can alleviate resource curse by promoting manufacturing and service transformation of industrial structure. The above findings not only provide empirical evidence for the sustainable promotion of digital government and the breaking of resource curse, but also provide a practical basis for optimizing and improving the construction of digital government.<p>
<p>
Lnenicka, M., et al. (2024). &quot;Government in the metaverse: Requirements and suitability for providing digital public services.&quot; <u>TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE</u> <b>203</b>.<p>
Digital government comprises all means to enable governments to interact with their constituents digitally. The metaverse provides a virtual reality environment where various activities can be carried out without physically visiting the places of interest, including the public authorities. Yet, how governments can use the metaverse is unknown. This paper aims to extend the understanding of the metaverse architecture requirements and their suitability for digital public services provision. We used the systematic literature review, experts' assessment using the Delphi method, and quantitative analysis to attain this goal. Our research contributes to the literature by eliciting the structure and composition of the functional and non-functional requirements. The contributions include (1) identification and classification of 50 functional and 16 non-functional metaverse-related architecture requirements, (2) determination and relevancy of 15 most important functional and 6 non-functional requirements for digital public services provision, and (3) suitability assessment of the 21 services recommended for provision in the EU's metaverse platform with the highest potential to attract users. These findings show that governments pose unique requirements on the metaverse. Not all types of services are suitable for providing in the metaverse. Those focused on empowering citizens and helping them to develop are most important.<p>
<p>
Madan, R. and M. Ashok (2023). &quot;AI adoption and diffusion in public administration: A systematic literature review and future research agenda.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(1).<p>
Artificial Intelligence (AI) implementation in public administration is gaining momentum heralded by the hope of smart public services that are personalised, lean, and efficient. However, the use of AI in public administration is riddled with ethical tensions of fairness, transparency, privacy, and human rights. We call these AI tensions. The current literature lacks a contextual and processual understanding of AI adoption and diffusion in public administration to be able to explore such tensions. Previous studies have outlined risks, benefits, and challenges with the use of AI in public administration. However, a large gap remains in understanding AI tensions as they relate to public value creation. Through a systematic literature review grounded in public value management and the resource-based view of the firms, we identify technology-organisational-environmental (TOE) contextual variables and absorptive capacity as factors influencing AI adoption as discussed in the literature. To our knowledge, this is the first paper that outlines distinct AI tensions from an AI implementation and diffusion perspective within public administration. We develop a future research agenda for the full AI innovation lifecycle of adoption, implementation, and diffusion.<p>
<p>
Medaglia, R., et al. (2023). &quot;Artificial Intelligence in Government: Taking Stock and Moving Forward.&quot; <u>SOCIAL SCIENCE COMPUTER REVIEW</u> <b>41</b>(1): 123-140.<p>
The use of artificial intelligence (AI) applications in government is receiving increasing attention from global research and practice communities. This article, introducing a Special Issue on Artificial Intelligence in Government published in the Social Science Computer Review, presents an overview of some of the main policy initiatives across the world in relation to AI in government and discusses the state of the art of existing research. Based on an analysis of current trends in research and practice, we highlight four areas to be the focus of future research on AI in government: governance of AI, trustworthy AI, impact assessment methodologies, and data governance.<p>
<p>
Mergel, I., et al. (2023). &quot;Implementing AI in the public sector.&quot; <u>PUBLIC MANAGEMENT REVIEW</u>.<p>
Artificial Intelligence (AI) has advanced as one of the most prominent technological innovations to push the conversation about the digital transformation of the public sector forward. This special issue focuses on actual implementation approaches or challenges that public managers are facing while they fulfil new policy that asks for the implementation of AI in public administrations. In addition to assessing the contributions of papers in this issue, we also provide a research agenda on how future research can fill some of the methodological, theoretical, and application gaps in the public management literature.<p>
<p>
Mikalef, P., et al. (2023). &quot;Examining how AI capabilities can foster organizational performance in public organizations.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(2).<p>
Developing the capacity to digitally transform through AI is becoming increasingly important for public orga-nizations, as a constantly growing number of their activities is now becoming AI-driven. This prompts an un-derstanding of how public organizations should organize in order to derive value from AI, as well as in which forms can value be realized. Against this background, this paper examines how AI capabilities can lead to organizational performance by inducing change in key organizational activities. Using a survey-based study, we collected data from European public organizations regarding the indirect effect AI capabilities have on organi-zational performance. Data was collected from 168 municipalities from three European countries (Norway, Germany, and Finland) and analyzed by means of structural equation modeling. Our findings show that AI ca-pabilities have a positive effect on process automation, cognitive insight generation, and cognitive engagement. While process automation and cognitive insights are having a positive effect on organizational performance, we found that cognitive engagement negatively affects organizational performance. Our findings document the key resources that constitute an AI capability and showcase the effects of fostering such capabilities on key orga-nizational activities, and in turn organizational performance.<p>
<p>
Mokander, J. and R. Schroeder (2024). &quot;Artificial Intelligence, Rationalization, and the Limits of Control in the Public Sector: The Case of Tax Policy Optimization.&quot; <u>SOCIAL SCIENCE COMPUTER REVIEW</u> <b>42</b>(6): 1359-1378.<p>
In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens' sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means - it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.<p>
<p>
Nascimento, P. V. M., et al. (2025). &quot;The future of AI in government services and global risks: insights from design fictions.&quot; <u>EUROPEAN JOURNAL OF FUTURES RESEARCH</u> <b>13</b>(1).<p>
The evolution of government services in the context of Artificial Intelligence (AI) and its long-term implications are relevant topics impacting society. Developments in this area are surrounded by controversies about what is technically possible, what is feasible in terms of implementation, and what is desirable. In addition, AI's ambiguous capacity to mitigate and accentuate global risks is remarkable. This research explores AI's long-term implications through a literature-based design fiction approach, constructing speculative scenarios to examine the potential consequences of AI adoption in governance. The findings highlight three critical dilemmas: (1) AI's dual role in enhancing efficiency while exacerbating algorithmic bias and surveillance concerns; (2) the potential displacement of human roles in public services, raising questions about accountability and transparency; and (3) the ethical trade-offs in AI-driven decision-making, particularly in law enforcement, healthcare, and education. These scenarios provide insights into the governance challenges AI may introduce, emphasizing the need for ethical guidelines, policy frameworks, and stakeholder engagement. By leveraging speculative narratives, this work contributes to Futures Research on AI in the public sector by offering a creative yet critical lens through which to explore its socio-technical impacts and global risks. These fictional stories will play a fundamental role in stimulating broader dialogues, exploring how AI may influence and redesign the roles played by professionals in government services and the citizens who use them.<p>
<p>
Neumann, O., et al. (2024). &quot;Exploring artificial intelligence adoption in public organizations: a comparative case study.&quot; <u>PUBLIC MANAGEMENT REVIEW</u> <b>26</b>(1): 114-141.<p>
Despite the enormous potential of artificial intelligence (AI), many public organizations struggle to adopt this technology. Simultaneously, empirical research on what determines successful AI adoption in public settings remains scarce. Using the technology organization environment (TOE) framework, we address this gap with a comparative case study of eight Swiss public organizations. Our findings suggest that the importance of technological and organizational factors varies depending on the organization's stage in the adoption process, whereas environmental factors are generally less critical. Accordingly, this study advances our theoretical understanding of the specificities of AI adoption in public organizations throughout the different adoption stages.<p>
<p>
Nyman, S., et al. (2024). &quot;Reforming work patterns or negotiating workloads? Exploring alternative pathways for digital productivity assistants through a problematization lens.&quot; <u>JOURNAL OF INFORMATION TECHNOLOGY</u> <b>39</b>(3): 503-520.<p>
Digital trace data can be used to capture organizational practices in granular detail and enable the automation of a wide range of managerial tasks. One example is Digital Productivity Assistants (DPA) that harness digital trace data about knowledge workers' performance and make targeted suggestions for how to improve and optimize their work patterns. Previous research shows that despite benevolent intentions to increase workers' wellbeing, DPA tend to introduce novel forms of exploitation and control. Inspired by Michel Foucault's philosophical strategy of 'problematization,' which emphasizes how practices are constructed in the form of problems that subsequently shape certain solutions, this paper takes a critical yet constructive view of DPA. Specifically, we conduct a genealogical reading of the DPA tool, Microsoft MyAnalytics, to investigate the problematics that have structured its emergence, as well as how its uses imply certain discursive commitments to philosophical and ethical questions. In the prevailing discourse, DPA cast digital trace data as a learning opportunity and thereby commit to individualizing the responsibility for handling the paradoxical nature of increasingly fluid work arrangements. Conversely, in our account of the history of MyAnalytics, we uncover a 'lost discourse' committed to trace data as a resource that can help knowledge workers negotiate excessive workloads. We propose the problematization lens as a way critically to articulate alternatives and speculate about instantiations of digital technology that today seem 'unthinkable'.<p>
<p>
Ossewaarde, M. and E. Gulenc (2020). &quot;National Varieties of Artificial Intelligence Discourses: Myth, Utopianism, and Solutionism in West European Policy Expectations.&quot; <u>COMPUTER</u> <b>53</b>(11): 53-61.<p>
Global actors and various nations have introduced artificial intelligence (AI) agendas where AI appears as a slippery, politicized phenomenon. In this article, we reveal that AI is mythologized as a benevolent, heroic force shaping nations in accord with political ambitions; that policies communicate utopian beliefs stating AI will transform national concerns favorably; and that technological solutionist expectations present AI as the answer to national challenges.<p>
<p>
Panagiotopoulos, P., et al. (2019). &quot;Public value creation in digital government.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(4).<p>
Public value theory offers innovative ways to plan, design, and implement digital government initiatives. The theory has gained the attention of researchers due to its powerful proposition that shifts the focus of public sector management from internal efficiency to value creation processes that occur outside the organization. While public value creation has become the expectation that digital government initiatives have to fulfil, there is lack of theoretical clarity on what public value means and on how digital technologies can contribute to its creation. The special issue presents a collection of six papers that provide new insights on how digital technologies support public value creation. Building on their contributions, the editorial note conceptualizes the realm of public value creation by highlighting: (1) the integrated nature of public value creation supported by digital government implementations rather than enhancing the values provided by individual technologies or innovations, (2) how the outcome of public value creation is reflected in the combined consumption of the various services enabled by technologies and (3) how public value creation is enabled by organizational capabilities and configurations.<p>
<p>
Popescu, R.-I., et al. (2023). &quot;The Contribution of Artificial Intelligence to Stimulating the Innovation of Educational Services and University Programs in Public Administration.&quot; <u>TRANSYLVANIAN REVIEW OF ADMINISTRATIVE SCIENCES</u>(70E): 85-108.<p>
In the new contemporary pandemic paradigm, higher education in public administration and beyond knows challenges, barriers, and opportunities for the academic process. Shocks, environmental changes and physical distancing in recent years have led to the implementation of efficient solutions in educational services, based on artificial intelligence (AI). Thus, in the global academic landscape, many international universities have adopted a 'chatbot', a digital interface designed to stimulate conversation with people. Modern algorithmic communications have effects, such as: increasing the number of enrollments in public administration programs, improving academic experience and active student participation, while reducing administrative tasks on university staff. This paper aims to provide a glimpse on the perceptions of the potential impact of conversational artificial intelligence on public administration (PA) programs from universities and to reflect on its implications for university leaders and staff work and also on students' engagement. The paper will focus on how AI tools will help university programs to be more effective, and how technology will support the limited human resources in this sector. In order to gather the data for this research, the interview was used as well as case studies from international universities that have implemented a chatbot. The research findings capture technological and digital advances that will continue to shape the higher education landscape and its curricula, especially in PA programs. As a result, leaders will need to monitor how artificial intelligence, in particular conversational agents, influences universities' images; attraction and retention for students in PA programs and other important partners; staff productivity, and how to be more proactive in initiating pilot projects. This is one of the few publications that looks at the expectations for conversational AI in higher education today. In this sense, implementing a chatbot can be a competitive advantage in a market where modern technologies weigh heavily and make a difference.<p>
<p>
Rizk, A. and I. Lindgren (2025). &quot;Automated decision-making in public administration: Changing the decision space between public officials and citizens.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>42</b>(3).<p>
Implementing Automated Decision-Making (ADM) systems in public administrations raises several tensions: between efficiency and ensuring fair decisions, between public transparency and individual privacy, and between standardization and discretion. To develop legitimate ADM systems that balance these tensions, we need to better understand the phenomenon on the societal, organizational and individual levels. To this end, we conduct a multidisciplinary literature review with the analysis utilizing Coleman's macro-micro model of social action, in which individual attitudes and actions relevant to ADM are related to ADM social structures and outcomes. We develop an ADM framework that captures and conceptualizes these macro-micro relationships and use this framework to identify gaps in research and motivate a research agenda. Our results also reveal a changing decision space between public officials and citizens that, if well investigated, may facilitate the development of citizen-centric ADM solutions and effective human-machine hybrids. We illustrate how the framework and ADM decision space can contribute to research, practice and policy.<p>
<p>
Ruvalcaba-Gomez, E. A. and V. H. Garcia-Benitez (2025). &quot;Governance of Artificial Intelligence in the Public Sector: Analysis of Public Policies in Spain and Mexico.&quot; <u>REVIEW OF POLICY RESEARCH</u>.<p>
In recent years, governments have changed the way they solve public problems by implementing new technologies, systems, and digital platforms. Recently, Artificial Intelligence (AI) applications have been popularized, disrupting societies and organizations. Thus, national governments have started to implement AI, something that has been reflected in several strategies, projects, and public policies. The main purpose of this research is to compare the AI public policies of two countries, Spain and M &amp; eacute;xico, from the theoretical perspective of comparative public policy. This research seeks to understand the relevance of government public policies, strategies, and government actions in the field of AI from the theoretical perspective of comparative public policy, as well as to highlight the elements and characteristics that make up the AI public policies for these countries. The results show that both countries share a political-social intention in the establishment of public policies and the development of AI. However, while Spain has consolidated projects and institutions that throwing public policy results, Mexico has not been able to consolidate public policies and institutions that take up the issue as a priority.(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(AI)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).En los &amp; uacute;ltimos a &amp; ntilde;os, los gobiernos han transformado su forma de resolver problemas p &amp; uacute;blicos mediante la implementaci &amp; oacute;n de nuevas tecnolog &amp; iacute;as, sistemas y plataformas digitales. Recientemente, las aplicaciones de la Inteligencia Artificial (IA) se han popularizado, transformando sociedades y organizaciones. Por ello, los gobiernos nacionales han comenzado a implementar la IA, lo que se ha reflejado en diversas estrategias, proyectos y pol &amp; iacute;ticas p &amp; uacute;blicas. El objetivo principal de esta investigaci &amp; oacute;n es comparar las pol &amp; iacute;ticas p &amp; uacute;blicas de IA de dos pa &amp; iacute;ses, Espa &amp; ntilde;a y M &amp; eacute;xico, desde la perspectiva te &amp; oacute;rica de la pol &amp; iacute;tica p &amp; uacute;blica comparada. Esta investigaci &amp; oacute;n busca comprender la relevancia de las pol &amp; iacute;ticas, estrategias y acciones gubernamentales en el &amp; aacute;mbito de la IA desde la perspectiva te &amp; oacute;rica de la pol &amp; iacute;tica p &amp; uacute;blica comparada, as &amp; iacute; como destacar los elementos y caracter &amp; iacute;sticas que conforman las pol &amp; iacute;ticas p &amp; uacute;blicas de IA en estos pa &amp; iacute;ses. Los resultados muestran que ambos pa &amp; iacute;ses comparten una intenci &amp; oacute;n pol &amp; iacute;tico-social en el establecimiento de pol &amp; iacute;ticas p &amp; uacute;blicas y el desarrollo de la IA. Sin embargo, mientras que Espa &amp; ntilde;a ha consolidado proyectos e instituciones que generan resultados en mate ia de pol &amp; iacute;ticas p &amp; uacute;blicas, M &amp; eacute;xico no ha logrado consolidar pol &amp; iacute;ticas e instituciones que prioricen el tema.<p>
<p>
Salem, A. M., et al. (2024). &quot;The Influence of Machine Learning on Enhancing Rational Decision-Making and Trust Levels in e-Government.&quot; <u>SYSTEMS</u> <b>12</b>(9).<p>
The rapid growth in the use of AI techniques, mainly machine learning (ML), is revolutionizing different industries by significantly enhancing decision-making processes through data-driven insights. This study investigates the influence of using ML, particularly supervised and unsupervised learning, on rational decision-making (RDM) within Jordanian e-government, focusing on the mediating role of trust. By analyzing the experiences of middle-level management within e-government in Jordan, the findings underscore that ML positively impacts the rational decision-making process in e-government. It enables more efficient and effective data gathering, improves the accuracy of data analysis, enhances the speed and accuracy of evaluating decision alternatives, and improves the assessment of potential risks. Additionally, this study reveals that trust plays a critical role in determining the effectiveness of ML adoption for decision-making, acting as a pivotal mediator that can either facilitate or impede the integration of these technologies. This study provides empirical evidence of how trust not only enhances the utilization of ML but also amplifies its positive impact on governance. The findings highlight the necessity of cultivating trust to ensure the successful deployment of ML in public administration, thereby enabling a more effective and sustainable digital transformation. Despite certain limitations, the outcomes of this study offer substantial insights for researchers and government policymakers alike, contributing to the advancement of sustainable practices in the e-government domain.<p>
<p>
Saveliev, A. and D. Zhurenkov (2021). &quot;Artificial intelligence and social responsibility: the case of the artificial intelligence strategies in the United States, Russia, and China.&quot; <u>KYBERNETES</u> <b>50</b>(3): 656-675.<p>
PurposeThe purpose of this paper is to review and analyze how the development and utilization of artificial intelligence (AI) technologies for social responsibility are defined in the national AI strategies of the USA, Russia and China.Design/methodology/approachThe notion of responsibility concerning AI is currently not legally defined by any country in the world. The authors of this research are going to use the methodology, based on Luciano Floridi's Unified framework of five principles for AI in society, to determine how social responsibility is implemented in the AI strategies of the USA, Russia and China.FindingsAll three strategies for the development of AI in the USA, Russia and China, as evaluated in the paper, contain some or other components aimed at achieving public responsibility and responsible use of AI. The Unified framework of five principles for AI in society, developed by L. Floridi, can be used as a viable assessment tool to determine at least in general terms how social responsibility is implied and implemented in national strategic documents in the field of AI. However, authors of the paper call for further development in the field of mutually recognizable ethical models for socially beneficial AI.Practical implicationsThis study allows us to better understand the linkages, overlaps and differences between modern philosophy of information, AI-ethics, social responsibility and government regulation. The analysis provided in this paper can serve as a basic blueprint for future attempts to define how social responsibility is understood and implied by government decision-makers.Originality/valueThe analysis provided in the paper, however general and empirical it may be, is a first-time example of how the Unified framework of five principles for AI in society can be applied as an assessment tool to determine social responsibility in AI-related official documents.<p>
<p>
Scutella, M., et al. (2024). &quot;Virtual agents in the public service: examining citizens' value-in-use.&quot; <u>PUBLIC MANAGEMENT REVIEW</u> <b>26</b>(1): 73-88.<p>
The importance of today's public sector delivering citizen-centric services enabled by technology is well recognized. To deliver such services, the public sector is turning to artificial intelligence, and in particular virtual agents (VA). This research examines how citizens gain value from interacting with VAs in a public sector setting. Through empirical research, utilizing transcripts from citizens' interactions with a VA, four dimensions of value-in-use were identified. This adds to the theoretical body of knowledge on value co-creation in public service settings and provides practical insights into how citizens use VAs and possible avenues for future investment and improvements.<p>
<p>
Sieber, R., et al. (2025). &quot;What is civic participation in artificial intelligence?&quot; <u>ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE</u> <b>52</b>(6): 1388-1406.<p>
There are increasing calls across disciplines and sectors that the public should participate in decisions about the use of artificial intelligence (AI). Public input in governmental decision-making is particularly crucial to promoting a well-functioning democracy and mitigating harms from AI. However, AI's opacity, mutability, and resource requirements impede meaningful civic engagement particularly in urban environments. Many prior systematic reviews of civic participation and AI draw on the smart city literature. However, several other disciplines influence civic participation in AI so a siloed disciplinary focus offers only partial guidance for participation's future role in AI. Our multi-disciplinary analysis blends works in smart cities, and in public policy, communication and, importantly, computer science to reveal distinct and highly variable pathways for civic participation. We use a sequence of manual and automated steps to conduct a structured literature analysis beginning with over 3,000 articles. We categorize authors' work on participation in AI into five themes: participation as a natural byproduct of automating government, participation facilitated through the medium of AI, participation in AI as quantification, participation as a technocracy of trust, and participation as meaningful. With few exceptions, authors seemed not to challenge the status quo nor diminish the authority of the experts. Authors focused on the processual without the influence and AI aided in that process orientation. We conclude that the future of public participation in AI requires careful attention to become meaningful including recognition of neoliberal intent and power differentials.<p>
<p>
Stahl, B. C. and D. Eke (2024). &quot;The ethics of ChatGPT - Exploring the ethical issues of an emerging technology.&quot; <u>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</u> <b>74</b>.<p>
This article explores ethical issues raised by generative conversational AI systems like ChatGPT. It applies established approaches for analysing ethics of emerging technologies to undertake a systematic review of possible benefits and concerns. The methodology combines ethical issues identified by Anticipatory Technology Ethics, Ethical Impact Assessment, and Ethical Issues of Emerging ICT Applications with AI-specific issues from the literature. These are applied to analyse ChatGPT's capabilities to produce humanlike text and interact seamlessly. The analysis finds ChatGPT could provide high-level societal and ethical benefits. However, it also raises significant ethical concerns across social justice, individual autonomy, cultural identity, and environmental issues. Key high-impact concerns include responsibility, inclusion, social cohesion, autonomy, safety, bias, accountability, and environmental impacts. While the current discourse focuses narrowly on specific issues such as authorship, this analysis systematically uncovers a broader, more balanced range of ethical issues worthy of attention. Findings are consistent with emerging research and industry priorities on ethics of generative AI. Implications include the need for diverse stakeholder engagement, considering benefits and risks holistically when developing applications, and multi-level policy interventions to promote positive outcomes. Overall, the analysis demonstrates that applying established ethics of technology methodologies can produce a rigorous, comprehensive foundation to guide discourse and action around impactful emerging technologies like ChatGPT. The paper advocates sustaining this broad, balanced ethics perspective as use cases unfold to realize benefits while addressing ethical downsides.<p>
<p>
Straub, V. J., et al. (2023). &quot;Artificial intelligence in government: Concepts, standards, and a unified framework.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(4).<p>
Recent advances in artificial intelligence (AI), especially in generative language modelling, hold the promise of transforming government. Given the advanced capabilities of new AI systems, it is critical that these are embedded using standard operational procedures, clear epistemic criteria, and behave in alignment with the normative expectations of society. Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls. However, the literature remains fragmented, with researchers in social science disciplines like public administration and political science, and the fast-moving fields of AI, ML, and robotics, all developing concepts in relative isolation. Although there are calls to formalize the emerging study of AI in government, a balanced account that captures the full depth of theoretical perspectives needed to understand the consequences of embedding AI into a public sector context is lacking. Here, we unify efforts across social and technical disciplines by first conducting an integrative literature review to identify and cluster 69 key terms that frequently co-occur in the multidisciplinary study of AI. We then build on the results of this bibliometric analysis to propose three new multifaceted concepts for understanding and analysing AI-based systems for government (AI-GOV) in a more unified way: (1) operational fitness, (2) epistemic alignment, and (3) normative divergence. Finally, we put these concepts to work by using them as dimensions in a conceptual typology of AI-GOV and connecting each with emerging AI technical measurement standards to encourage operationalization, foster cross-disciplinary dialogue, and stimulate debate among those aiming to rethink government with AI.<p>
<p>
Sun, T. Q. and R. Medaglia (2019). &quot;Mapping the challenges of Artificial Intelligence in the public sector: Evidence from public healthcare.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(2): 368-383.<p>
The nascent adoption of Artificial Intelligence (AI) in the public sector is being assessed in contradictory ways. But while there is increasing speculation about both its dangers and its benefits, there is very little empirical research to substantiate them. This study aims at mapping the challenges in the adoption of AI in the public sector as perceived by key stakeholders. Drawing on the theoretical lens of framing, we analyse a case of adoption of the AI system IBM Watson in public healthcare in China, to map how three groups of stakeholders (government policy-makers, hospital managers/doctors, and Information Technology (IT) firm managers) perceive the challenges of AI adoption in the public sector. Findings show that different stakeholders have diverse, and sometimes contradictory, framings of the challenges. We contribute to research by providing an empirical basis to claims of AI challenges in the public sector, and to practice by providing four sets of guidelines for the governance of AI adoption in the public sector.<p>
<p>
Tan, W. J., et al. (2024). &quot;Unlocking green potential: The digital government-driven revolution in corporate green innovation.&quot; <u>ECONOMIC ANALYSIS AND POLICY</u> <b>83</b>: 60-79.<p>
This study leverages data of China's A-share listed companies spanning from 2010 to 2020, using the Internet Plus Government Services initiative as a quasi-natural experiment. By employing the difference-in-differences method, it empirically examines the empowering effects and underlying mechanisms of digital government on corporate green innovation. Research findings are as follows: 1) Digital government significantly enhances both the quantity and quality of corporate green innovation. 2) Corporate green innovation can be enhanced by digital government through promoting the digitization of the business environment, reducing transaction costs for enterprises, increasing R&amp;D investment and green investments. 3) The enabling effects of digital government on corporate green innovation are particularly evident in companies with better environmental information disclosure, elevated levels of digital technology application, non-heavy-polluting industries, and enterprises located in regions with stricter environmental regulations. From the perspective of internalizing digital technology into government transformation, this study provides important insights for the future coordination of policies related to digital and green development.<p>
<p>
Tlili, A., et al. (2024). &quot;Artificial intelligence ethics in services: are we paying attention to that?!&quot; <u>SERVICE INDUSTRIES JOURNAL</u> <b>44</b>(15-16): 1093-1116.<p>
Scant information exists in the literature on the ethical considerations when adopting and implementing Artificial Intelligence (AI) in services. To address this research gap, this study conducts a bibliometric analysis of 286 research articles, identified from the Scopus and Web of Science databases, on AI ethics in services. The findings revealed that most of the research on AI ethics in services is from the United Kingdom, the U.S., and China. The co-occurrence analysis further revealed that AI ethics is a complex dimension, where several ethic types are found, namely digital, business, machine, and artificial. Additionally, AI effects should be considered from micro, meso, and macro perspectives to ensure that AI systems are ethically correct. The thematic findings highlighted that for AI systems to be safe and effective in industry, they should be responsible and human-centered. Developing such systems requires defining and implementing several features, including transparency, responsibility, explainability, and accountability. Finally, the obtained findings highlighted the need for increasing awareness of AI ethics in services as well as developing regulatory frameworks and laws in this context. The findings of this study can help various stakeholders (policymakers, developers, business owners, etc.) promote the safe and effective adoption of AI in industry.<p>
<p>
Tornberg, P., et al. (2025). &quot;Artificial intelligence and the state: Seeing like an artificial neural network.&quot; <u>BIG DATA &amp; SOCIETY</u> <b>12</b>(2).<p>
The emergence of the modern state was closely intertwined with the advent of statistics and demographic data. Today, we are witnessing the ascent of artificial intelligence as a new technology of governance. This article seeks to lay the groundwork for a research agenda at the intersection of the state and artificial intelligence, unpacking the notion of &quot;AI&quot; and examining the consequences of the state transitioning from statistics to artificial intelligence as the means of &quot;seeing&quot; its subjects. The first part of the article argues that artificial intelligence represents a fundamental epistemic shift: from variables to patterns, from rules to associations, from surveys to sensors. This transition may transform governance and biopolitics, and with them, the very meanings of concepts such as citizenship, democracy, and population. In the second part of the article, the article draws on the literature on socio-technical transitions to conceptualize the integration of artificial intelligence into state practices, offering a framework to guide empirical research on how artificial intelligence is transforming governance.<p>
<p>
Trajkovski, G. (2024). &quot;Bridging the public administration-AI divide: A skills perspective.&quot; <u>PUBLIC ADMINISTRATION AND DEVELOPMENT</u> <b>44</b>(5): 412-426.<p>
The advent of Artificial Intelligence (AI) is set to revolutionize governance and public administration, presenting both opportunities and challenges. This paper provides a roadmap for public agencies, detailing steps from preparation to mainstream AI implementation. It proposes a skills framework encompassing technical, ethical, legal, and management aspects, supplemented by continuous training recommendations. Emphasizing a human-centric and ethical approach, it aims to foster innovative and responsible governance. Collaboration is highlighted as vital for accelerating AI adoption and equipping administrators with tools to navigate this complex yet promising landscape. The paper also addresses the equality and inclusion challenges posed by AI, particularly in bridging the divide between the Global North and Global South, using international examples from both developed and developing countries. These insights ensure a comprehensive perspective on AI integration in public administration, promoting a holistic and nuanced approach to addressing these challenges.<p>
<p>
Twizeyimana, J. D. and A. Andersson (2019). &quot;The public value of E-Government - A literature review.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>36</b>(2): 167-178.<p>
This study organizes existing research on the public value of e-government in order to investigate the current state and what value e-government is supposed to yield. The two questions that guided the research were: (1) What is the current state of research on the public value of e-government? And (2) What value is e-government supposed to yield? Six, sometimes overlapping, values were found: Improved public services; improved administrative efficiency; Open Government (OG) capabilities; improved ethical behaviour and professionalism; improved trust and confidence in government; and improved social value and well-being. These six public value dimensions were thereafter generalized into three overarching, and also overlapping, public value dimensions of Improved Public Services, Improved Administration, and Improved Social Value. The improved public services dimension influences other dimensions. Hence, this literature study theorizes a descriptive and multidimensional framework that can improve our understanding of the public value of e-government from different viewpoints, and the overlap between them in actual e-government designs and implementations. Regarding the current state of research on the public value this study found a lack of research on the public value of e-government, especially, in the context of developing countries - and more importantly - a total absence of this kind of research in the Least Developed Countries (LDCs). There is also a lack of comparative studies at national, regional, and project level; and a lack of research on the generative perspective.<p>
<p>
van Noordt, C., et al. (2025). &quot;Policy initiatives for Artificial Intelligence-enabled government: An analysis of national strategies in Europe.&quot; <u>PUBLIC POLICY AND ADMINISTRATION</u> <b>40</b>(2): 215-253.<p>
Governments have been putting forward various proposals to stimulate and facilitate research on Artificial Intelligence (AI), develop new solutions, and adopt these technologies within their economy and society. Despite this enthusiasm, however, the adoption and deployment of AI technologies within public administrations face many barriers, limiting administrations from drawing on the benefits of these technologies. These barriers include the lack of quality data, ethical concerns, unawareness of what AI could mean, lack of expertise, legal limitations, the need for inter-organisational collaboration, and others. AI strategy documents describe plans and goals to overcome the barriers to introducing AI in societies. Drawing on an analysis of 26 AI national strategy documents in Europe analysed through the policy instrument lens, this study shows that there is a strong focus on initiatives to improve data-related aspects and collaboration with the private sector, and that there are limited initiatives to improve internal capacity or funding.<p>
<p>
van Noordt, C. and G. Misuraca (2022). &quot;Artificial intelligence for the public sector: results of landscaping the use of AI in government across the European Union.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(3).<p>
Artificial Intelligence is increasingly being used by public sector organisations. Previous research highlighted that the use of AI technologies in government could improve policy making processes, public service delivery and the internal management of public administrations. In this article, we explore to which extent the use of AI in the public sector impacts these core governance functions. Findings from the review of a sample of 250 cases across the European Union, show that AI is used mainly to support improving public service delivery, followed by enhancing internal management and only in a limited number assist directly or indirectly policy decision-making. The analysis suggests that different types of AI technologies and applications are used in different governance functions, highlighting the need to further in-depth investigation to better understand the role and impact of use in what is being defined the governance &quot;of, with and by AI&quot;.<p>
<p>
van Noordt, C. and L. Tangi (2023). &quot;The dynamics of AI capability and its influence on public value creation of AI within public administration.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(4).<p>
Artificial Intelligence (AI) technologies in public administration are gaining increasing attention due to the potential benefits they can provide in improving governmental operations. However, translating technological opportunities into concrete public value for public administrations is still limited. One of the factors hindering this progress is the lack of AI capability within public organisations. The research found that various components of AI capability are essential for successfully developing and using AI technologies, including tangible, intangible, and human-related factors. There is a distinction between the AI capability to develop and the AI capability to implement AI technologies, with more administrations capable of the former but finding difficulties in the latter. A lack of in-house technical expertise to maintain and update the AI systems, legal challenges in deploying developed AI systems, and the capability to introduce changes in the organisation to ensure the system remains operational and used by relevant end-users are among the most critical limiting factors for long-term use of AI by public administrations. The research underlines the strong complementarity between historical eGovernment developments and the capability to deploy AI technologies. The study suggests that funding alone may not be enough to acquire AI capability, and public administrations need to focus on both the capability to develop and implement AI technologies. The research emphasizes that human skillsets, both technical and non-technical, are essential for the successful implementation of AI in public administration.<p>
<p>
Viscusi, G., et al. (2020). &quot;Public Strategies for Artificial Intelligence: Which Value Drivers?&quot; <u>COMPUTER</u> <b>53</b>(10): 38-46.<p>
We question the values that inform the artificial intelligence (AI) strategies developed by governments and institutions at the global level. In particular, we investigate the connection between governments? and institutions? fundamental values, second-order values associated with AI, and the values emerging from the analysis of AI strategies.<p>
<p>
Wang, C., et al. (2021). &quot;Public and private value creation using artificial intelligence: An empirical study of AI voice robot users in Chinese public sector.&quot; <u>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</u> <b>61</b>.<p>
Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore's public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.<p>
<p>
Wang, Y. (2025). &quot;Is the public willing to provide personal information for processing by government AI? An experimental study based on regulatory commitment and algorithmic transparency.&quot; <u>JOURNAL OF ASIAN PUBLIC POLICY</u>.<p>
The role of government AI relies on the dynamic interaction between public input and AI output, and at the same time brings new privacy concerns. So, is the public willing to provide personal information for processing by government AI? Established studies have not yet discussed this topic in depth. Using technology enactment theory, this study employs a survey experiment to analyse the effects of government regulatory commitment and algorithmic transparency on the public's willingness to share personal information.The findings indicate that although both factors have a significant effect on the public's willingness to share personal information, however,the effect of algorithmic transparency is more nuanced: The public's willingness to share personal information relies more on government regulatory guarantees than on an understanding of the algorithmic decision-making process, and may even be inhibited by the exposure of AI's deep data analytics capabilities, which activates the public's wariness of deep data use. Technology trust is the intermediary factor affecting the public's willingness to share personal information. These insights offer theoretical and policy implications for designing accountable, citizen-centred government AI systems and improving public engagement in data-driven governance.<p>
<p>
Wang, Y.-F., et al. (2025). &quot;Citizens' intention to follow recommendations from a government-supported AI-enabled system.&quot; <u>PUBLIC POLICY AND ADMINISTRATION</u> <b>40</b>(2): 372-400.<p>
Artificial intelligence (AI) applications in public services are an emerging and crucial issue in the modern world. Many countries utilize AI-enabled systems to serve citizens and deliver public services. Although AI can bring more efficiency and responsiveness, this technology raises privacy and social inequality concerns. From the perspective of behavioral public administration (BPA), citizens' use of AI-enabled systems depends on their perception of this technology. This study proposes a conceptual framework connecting citizens' perceptions, trust, and intention to follow instructions from the government-supported AI-enabled recommendation system in the pandemic. Our study launches an online-based experimental survey and analyzes the data with the partial least square structural equation model (PLS-SEM). The research findings suggest that algorithmic transparency increases trust in the recommendations, but privacy concerns decrease the trust when the system asks for sensitive information. Additionally, citizens familiar with technologies are more likely to trust the recommendations in the feature-based communication strategy. Finally, trust in the recommendations can mediate the impacts of citizens' perceptions of the AI system. This study clarifies the effects of perceptions, identifies the role of trust, and explores the communication strategies in citizens' intention to follow the AI-enabled system recommendations. The results can deepen AI research in public administration and provide policy suggestions for the public sector to develop strategies to increase policy compliance with system recommendations.<p>
<p>
Willems, J., et al. (2022). &quot;Ethics of robotized public services: The role of robot design and its actions.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(2).<p>
Public administrations invest heavily in the development of 'smart' public services, including autonomous public service robots. Since public service robots are designed to operate unsupervised, robots must interact in an ethically acceptable way with citizens. Robots are often designed to provide a comfortable interaction with citizens, which can be achieved by making the robot's appearance and actions more human-like. This raises the question whether a human-like design affects the ethicalness evaluation of a robot's actions. In a laboratory experiment with eye-tracking (n(1) = 156) and a representative, online vignette experiment (n(2) = 1339), we find that a more human-like robot design draws more visual attention than a robot with a less human-like design. However, the robot's appearance does not affect the ethicalness evaluation of the robot's behavior. In contrast, our results show that it is not the more human-like appearance that influences evaluations of ethicalness, but a robot's ethical actions influence the extent to which it is perceived as human. We frame our findings in the scientific and practitioner debates on ethical rule-setting for (public) service robots.<p>
<p>
Wilson, C. (2022). &quot;Public engagement and AI: A values analysis of national strategies.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(1).<p>
Calls for public engagement and participation in AI governance align strongly with a public value management approach to public administration. Simultaneously, the prominence of commercial vendors and consultants in AI discourse emphasizes market value and efficiency in a way often associated with the private sector and New Public Management. To understand how this might influence the consolidation of AI governance regimes and decision-making by public administrators, 16 national strategies for AI are subjected to content analysis. References to the public's role and public engagement mechanisms are mapped across national strategies, as is the articulation of values related to professionalism, efficiency, service, engagement, and the private sector. Though engagement rhetoric is common, references to specific engagement mechanisms and activities are rare. Analysis of value relationships highlights congruence of engagement values with professionalism and private sector values, and raises concerns about neoliberal technology frames that normalize AI, obscuring policy complexity and trade-offs.<p>
<p>
Wilson, C. and H. Broomfield (2023). &quot;Learning how to do AI: managing organizational boundaries in an intergovernmental learning forum.&quot; <u>PUBLIC MANAGEMENT REVIEW</u> <b>25</b>(10): 1938-1957.<p>
This analysis applies boundary theory to public manager efforts to overcome AI capacity gaps through a public sector collaborative learning forum. Administrative and interview data identify the types of knowledge managers are able to access, the types of organizational differences that influence learning, and the strategies public managers use to overcome them. Analysis suggests that unstructured learning fora are better suited to the transfer of tacit procedural knowledge than declarative knowledge about AI, and emphasizes the importance of social trust and network structure to overcome knowledge gaps through peer learning.<p>
<p>
Yang, X. R., et al. (2024). &quot;Does digital government transformation drive regional green innovation? Evidence from cities in China.&quot; <u>ENERGY POLICY</u> <b>187</b>.<p>
With the escalating environmental challenges, regional green innovation, as the key to achieving the goal of environmental sustainability, has evolved into a focal point of societal apprehension. The external environment of regional green innovation has changed amid the digital government transformation (DGT). However, there hasn't been much discussion of how DGT affects regional green innovation. Therefore, to explore the impact of DGT on regional green innovation and its specific mechanism, we use the China Mobile Online Service Platform (MOSP) adoption as a quasi -natural experiment, based on panel data on 288 cities in China from 2006 to 2020, and apply a time -varying difference -in -differences model. Our study finds that DGT affects regional green innovation in a positive way. Green financial development and green -talent gathering mediate the DGT's influence on regional green innovation. The government's policy attention to green development and technology research plays a positive moderating role between DGT and regional green innovation. Our study advances the research on DGT's contribution to environmental sustainability by confirming the positive effects of DGT on regional green innovation.<p>
<p>
Yigitcanlar, T., et al. (2023). &quot;Artificial intelligence in local government services: Public perceptions from Australia and Hong Kong.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>40</b>(3).<p>
Despite the exponential growth in the popularity of artificial intelligence (AI), our knowledge on the public perception of AI, especially in the context of local government services, is still limited. To bridge this gap, this study aims to provide empirical evidence and insights into public perceptions concerning the use of AI in local government services. Our methodological approach involves collecting data via an online survey from the residents of three major Australian cities-i.e., Sydney, Melbourne, Brisbane-and Hong Kong (n = 850), and performing statistical analyses. We found that: (a) Ease of using AI is significantly and positively influenced by attitude towards AI; (b) Attitude towards AI significantly and positively influences perceived usefulness of AI in local government services; (c) AI is seen useful in resource management and to improve delivery of service, reduction of cost to provide urban-service, improvement of public safety, and monitoring the effectiveness of strategies to manage environmental crisis, and; (d) AI is more positively perceived by Australians in comparison to Hong Kongers, indicating the impact of contextual and cultural differences. The research findings inform local government authorities-e.g., urban policymakers, managers, and planners-on their AI policy, planning and implementation decisions.<p>
<p>
Yigitcanlar, T., et al. (2021). &quot;Green Artificial Intelligence: Towards an Efficient, Sustainable and Equitable Technology for Smart Cities and Futures.&quot; <u>SUSTAINABILITY</u> <b>13</b>(16).<p>
Smart cities and artificial intelligence (AI) are among the most popular discourses in urban policy circles. Most attempts at using AI to improve efficiencies in cities have nevertheless either struggled or failed to accomplish the smart city transformation. This is mainly due to short-sighted, technologically determined and reductionist AI approaches being applied to complex urbanization problems. Besides this, as smart cities are underpinned by our ability to engage with our environments, analyze them, and make efficient, sustainable and equitable decisions, the need for a green AI approach is intensified. This perspective paper, reflecting authors' opinions and interpretations, concentrates on the &quot;green AI&quot; concept as an enabler of the smart city transformation, as it offers the opportunity to move away from purely technocentric efficiency solutions towards efficient, sustainable and equitable solutions capable of realizing the desired urban futures. The aim of this perspective paper is two-fold: first, to highlight the fundamental shortfalls in mainstream AI system conceptualization and practice, and second, to advocate the need for a consolidated AI approach-i.e., green AI-to further support smart city transformation. The methodological approach includes a thorough appraisal of the current AI and smart city literatures, practices, developments, trends and applications. The paper informs authorities and planners on the importance of the adoption and deployment of AI systems that address efficiency, sustainability and equity issues in cities.<p>
<p>
Yigitcanlar, T., et al. (2024). &quot;Artificial intelligence and the local government: A five-decade scientometric analysis on the evolution, state-of-the-art, and emerging trends.&quot; <u>CITIES</u> <b>152</b>.<p>
In recent years, the rapid advancement of artificial intelligence (AI) technologies has significantly impacted various sectors, including public governance at the local level. However, there exists a limited understanding of the overarching narrative surrounding the adoption of AI in local governments and its future. Therefore, this study aims to provide a comprehensive overview of the evolution, current state-of-the-art, and emerging trends in the adoption of AI in local government. A comprehensive scientometric analysis was conducted on a dataset comprising 7112 relevant literature records retrieved from the Scopus database in October 2023, spanning over the last five decades. The study findings revealed the following key insights: (a) exponential technological advancements over the last decades ushered in an era of AI adoption by local governments; (b) the primary purposes of AI adoption in local governments include decision support, automation, prediction, and service delivery; (c) the main areas of AI adoption in local governments encompass planning, analytics, security, surveillance, energy, and modelling; and (d) under-researched but critical research areas include ethics of and public participation in AI adoption in local governments. This study informs research, policy, and practice by offering a comprehensive understanding of the literature on AI applications in local governments, providing valuable insights for stakeholders and decision-makers.<p>
<p>
Zaidan, E. and I. A. Ibrahim (2024). &quot;AI Governance in a Complex and Rapidly Changing Regulatory Landscape: A Global Perspective.&quot; <u>HUMANITIES &amp; SOCIAL SCIENCES COMMUNICATIONS</u> <b>11</b>(1).<p>
The rapid advancement and deployment of Artificial Intelligence (AI) poses significant regulatory challenges for societies. While it has the potential to bring many benefits, the risks of commercial exploitation or unknown technological dangers have led many jurisdictions to seek a legal response before measurable harm occurs. However, the lack of technical capabilities to regulate this sector despite the urgency to do so resulted in regulatory inertia. Given the borderless nature of this issue, an internationally coordinated response is necessary. This article focuses on the theoretical framework being established in relation to the development of international law applicable to AI and the regulatory authority to create and monitor enforcement of said law. The authors argue that the road ahead remains full of obstacles that must be tackled before the above-mentioned elements see the light despite the attempts being made currently to that end.<p>
<p>
Zhang, D., et al. (2022). &quot;Orchestrating artificial intelligence for urban sustainability.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>39</b>(4).<p>
Artificial intelligence (AI) is regarded as the next digital frontier in government, with many potential applications for economic development as well as sustainable urbanization. Governments have started experimenting with AI, but empirical research on how to leverage and implement AI remains limited. This study analyzed two cases of AI implementation in a large city and identified various AI capabilities useful for government. More importantly, purposeful orchestration of AI-related resources such as data, knowledge, algorithms, and information systems is necessary for developing strong AI capabilities. The findings indicate two different types of orchestration: policydriven orchestration focuses on the integration of resources, while innovation-driven orchestration focuses on triangulation. This study contributes to the growing body of knowledge on AI in government by revealing and conceptualizing different paths and approaches to AI implementation. They also serve to inform practitioners' planning of AI implementation.<p>
<p>
Zhang, W., et al. (2021). &quot;Factors influencing the use of artificial intelligence in government: Evidence from China.&quot; <u>TECHNOLOGY IN SOCIETY</u> <b>66</b>.<p>
Some studies have discussed the potential and challenges related to the use of artificial intelligence (AI) in government. However, there are few empirical studies that have examined factors that influence the use of AI in government. By collecting policy documents and empirical data from the government, IT enterprises, and the public in China, we identified the influencing factors in the three stages of government adoption, implementation, and decision-making. The research results show that the influencing factors of government application of AI are different at different stages and with different stakeholders' backgrounds.<p>
<p>
Zuiderwijk, A., et al. (2021). &quot;Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda.&quot; <u>GOVERNMENT INFORMATION QUARTERLY</u> <b>38</b>(3).<p>
To lay the foundation for the special issue that this research article introduces, we present 1) a systematic review of existing literature on the implications of the use of Artificial Intelligence (AI) in public governance and 2) develop a research agenda. First, an assessment based on 26 articles on this topic reveals much exploratory, conceptual, qualitative, and practice-driven research in studies reflecting the increasing complexities of using AI in government - and the resulting implications, opportunities, and risks thereof for public governance. Second, based on both the literature review and the analysis of articles included in this special issue, we propose a research agenda comprising eight process-related recommendations and seven content-related recommendations. Process-wise, future research on the implications of the use of AI for public governance should move towards more public sector-focused, empirical, multidisciplinary, and explanatory research while focusing more on specific forms of AI rather than AI in general. Content-wise, our research agenda calls for the development of solid, multidisciplinary, theoretical foundations for the use of AI for public governance, as well as investigations of effective implementation, engagement, and communication plans for government strategies on AI use in the public sector. Finally, the research agenda calls for research into managing the risks of AI use in the public sector, governance modes possible for AI use in the public sector, performance and impact measurement of AI use in government, and impact evaluation of scaling-up AI usage in the public sector.<p>
<p>
</body>
</html>
